{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be7be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc450bdf-6484-46c8-af39-b78696ec5106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.TextPreprocessor import TextPreprocessor\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06325341",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3492953-3cc4-4392-b9e2-ff5bdbc0495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from hugging face \n",
    "# cnamuangtoun/resume-job-description-fit\n",
    "\n",
    "ds = load_dataset(\"cnamuangtoun/resume-job-description-fit\")\n",
    "train_df = ds['train'].to_pandas()\n",
    "test_df = ds['test'].to_pandas()\n",
    "\n",
    "# Create train/validation split\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.30,\n",
    "                                   stratify=train_df[\"label\"], random_state=42)\n",
    "\n",
    "def map_multiclass(dfs: List):\n",
    "\n",
    "    # Create label mapping\n",
    "    label_to_id = {\"Good Fit\": 0, \"No Fit\": 2, \"Potential Fit\":1}\n",
    "\n",
    "    for df in dfs:\n",
    "        df[\"label\"] = df[\"label\"].map(label_to_id)\n",
    "\n",
    "    return dfs[0], dfs[1], dfs[2]\n",
    "\n",
    "def map_binaryclass(dfs: List):\n",
    "\n",
    "    # Create label mapping\n",
    "    label_to_id = {\"Good Fit\": 0, \"No Fit\": 1, \"Potential Fit\":0}\n",
    "\n",
    "    for df in dfs:\n",
    "        df[\"label\"] = df[\"label\"].map(label_to_id)\n",
    "\n",
    "    return dfs[0], dfs[1], dfs[2]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def show_split_stats(train_df: pd.DataFrame,\n",
    "                     val_df: pd.DataFrame,\n",
    "                     test_df: pd.DataFrame,\n",
    "                     label_col: str = \"label\"):\n",
    "    header = (\n",
    "        f\"Data loaded and split:\\n\"\n",
    "        f\"  â€¢ Training:   {len(train_df):>6} samples\\n\"\n",
    "        f\"  â€¢ Validation: {len(val_df):>6} samples\\n\"\n",
    "        f\"  â€¢ Test:       {len(test_df):>6} samples\\n\"\n",
    "        f\"\\nTraining label distribution:\"\n",
    "    )\n",
    "\n",
    "    # Counts and percentages side-by-side\n",
    "    counts = train_df[label_col].value_counts(dropna=False)\n",
    "    pct = (counts / counts.sum() * 100).round(1)\n",
    "    stats = pd.concat([counts.rename(\"count\"), pct.rename(\"%\")], axis=1)\n",
    "\n",
    "    print(header)\n",
    "    print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b52113e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â€” Binary â€”\n",
      "Data loaded and split:\n",
      "  â€¢ Training:     4368 samples\n",
      "  â€¢ Validation:   1873 samples\n",
      "  â€¢ Test:         1759 samples\n",
      "\n",
      "Training label distribution:\n",
      "       count     %\n",
      "label             \n",
      "1       2200  50.4\n",
      "0       2168  49.6\n",
      "\n",
      "â€” Multiclass â€”\n",
      "Data loaded and split:\n",
      "  â€¢ Training:     4368 samples\n",
      "  â€¢ Validation:   1873 samples\n",
      "  â€¢ Test:         1759 samples\n",
      "\n",
      "Training label distribution:\n",
      "       count     %\n",
      "label             \n",
      "2       2200  50.4\n",
      "1       1089  24.9\n",
      "0       1079  24.7\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Comparing multiclass dataset and binary dataset stats\n",
    "\"\"\"\n",
    "\n",
    "dfs = {\n",
    "    kind: dict(zip([\"train\", \"val\", \"test\"],\n",
    "                   func([train_df.copy(), val_df.copy(), test_df.copy()])))\n",
    "    for kind, func in {\n",
    "        \"binary\": map_binaryclass,\n",
    "        \"multiclass\": map_multiclass\n",
    "    }.items()\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ quick sanity-check â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for kind, splits in dfs.items():\n",
    "    print(f\"\\nâ€” {kind.capitalize()} â€”\")\n",
    "    show_split_stats(splits[\"train\"], splits[\"val\"], splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9e913f7-7f0d-4f22-ac53-610d9f2b0d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â€” Binary (after preprocessing) â€”\n",
      "Data loaded and split:\n",
      "  â€¢ Training:     4368 samples\n",
      "  â€¢ Validation:   1873 samples\n",
      "  â€¢ Test:         1759 samples\n",
      "\n",
      "Training label distribution:\n",
      "       count     %\n",
      "label             \n",
      "1       2200  50.4\n",
      "0       2168  49.6\n",
      "\n",
      "â€” Multiclass (after preprocessing) â€”\n",
      "Data loaded and split:\n",
      "  â€¢ Training:     4368 samples\n",
      "  â€¢ Validation:   1873 samples\n",
      "  â€¢ Test:         1759 samples\n",
      "\n",
      "Training label distribution:\n",
      "       count     %\n",
      "label             \n",
      "2       2200  50.4\n",
      "1       1089  24.9\n",
      "0       1079  24.7\n"
     ]
    }
   ],
   "source": [
    "tp = TextPreprocessor(enable_stopwords=True, enable_lemmatizer=True)\n",
    "\n",
    "for kind, splits in dfs.items():\n",
    "    for split_name, df in splits.items():\n",
    "        dfs[kind][split_name] = tp.process_dataset(df, clean_text=True, remove_stop_words=True, lemmatize=True)\n",
    "\n",
    "for kind, splits in dfs.items():\n",
    "    print(f\"\\nâ€” {kind.capitalize()} (after preprocessing) â€”\")\n",
    "    show_split_stats(splits[\"train\"], splits[\"val\"], splits[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e4a2c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ—‚  Exporting binary dataset â†’ ../data/full_process/undersampled/binary  (strategy=oversample)\n",
      "  train  | before: {1: 2200, 0: 2168}  â†’  after: {0: 2200, 1: 2200}\n",
      "  val    | before: {0: 930, 1: 943}  â†’  after: {0: 943, 1: 943}\n",
      "  test   | before: {1: 857, 0: 902}  â†’  after: {1: 902, 0: 902}\n",
      "\n",
      "ðŸ—‚  Exporting multiclass dataset â†’ ../data/full_process/undersampled/multiclass  (strategy=oversample)\n",
      "  train  | before: {2: 2200, 1: 1089, 0: 1079}  â†’  after: {2: 2200, 1: 2200, 0: 2200}\n",
      "  val    | before: {0: 463, 2: 943, 1: 467}  â†’  after: {1: 943, 2: 943, 0: 943}\n",
      "  test   | before: {2: 857, 1: 444, 0: 458}  â†’  after: {1: 857, 2: 857, 0: 857}\n",
      "\n",
      "âœ… All balanced splits saved to: /home/maveron/Projects/Resume-Screener/data/full_process/undersampled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20562/3153678593.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(target, replace=True, random_state=SEED))\n",
      "/tmp/ipykernel_20562/3153678593.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(target, replace=True, random_state=SEED))\n",
      "/tmp/ipykernel_20562/3153678593.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(target, replace=True, random_state=SEED))\n",
      "/tmp/ipykernel_20562/3153678593.py:50: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"created_at\": datetime.utcnow().isoformat() + \"Z\",\n",
      "/tmp/ipykernel_20562/3153678593.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(target, replace=True, random_state=SEED))\n",
      "/tmp/ipykernel_20562/3153678593.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(target, replace=True, random_state=SEED))\n",
      "/tmp/ipykernel_20562/3153678593.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(target, replace=True, random_state=SEED))\n",
      "/tmp/ipykernel_20562/3153678593.py:50: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"created_at\": datetime.utcnow().isoformat() + \"Z\",\n"
     ]
    }
   ],
   "source": [
    "import os, pickle, json, pathlib, random\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "DEST_DIR         = pathlib.Path(\"../data/full_process/undersampled\")\n",
    "BALANCE_STRATEGY = \"oversample\"        # \"oversample\" | \"undersample\"\n",
    "SEED             = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "def balance_df(df, label_col=\"label\", strategy=\"oversample\"):\n",
    "    counts = df[label_col].value_counts()\n",
    "    if strategy == \"oversample\":\n",
    "        target = counts.max()\n",
    "        balanced = (\n",
    "            df.groupby(label_col, group_keys=False)\n",
    "              .apply(lambda g: g.sample(target, replace=True, random_state=SEED))\n",
    "        )\n",
    "    elif strategy == \"undersample\":\n",
    "        target = counts.min()\n",
    "        balanced = (\n",
    "            df.groupby(label_col, group_keys=False)\n",
    "              .apply(lambda g: g.sample(target, replace=False, random_state=SEED))\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"strategy must be 'oversample' or 'undersample'\")\n",
    "    return balanced.sample(frac=1, random_state=SEED)\n",
    "\n",
    "for kind, splits in dfs.items():\n",
    "    out_dir = DEST_DIR / kind\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"\\nðŸ—‚  Exporting {kind} dataset â†’ {out_dir}  (strategy={BALANCE_STRATEGY})\")\n",
    "\n",
    "    for split_name, df in splits.items():\n",
    "        before = Counter(df[\"label\"])\n",
    "        df_bal = balance_df(df, label_col=\"label\", strategy=BALANCE_STRATEGY)\n",
    "        after  = Counter(df_bal[\"label\"])\n",
    "\n",
    "        print(f\"  {split_name:<5}  | before: {dict(before)}  â†’  after: {dict(after)}\")\n",
    "\n",
    "        X = df_bal.drop(columns=[\"label\"])\n",
    "        y = df_bal[\"label\"]\n",
    "\n",
    "        with open(out_dir / f\"X_{split_name}.pkl\", \"wb\") as fx:\n",
    "            pickle.dump(X, fx, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(out_dir / f\"y_{split_name}.pkl\", \"wb\") as fy:\n",
    "            pickle.dump(y, fy, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    manifest = {\n",
    "        \"created_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "        \"balance_strategy\": BALANCE_STRATEGY,\n",
    "        \"seed\": SEED,\n",
    "        \"files\": sorted([p.name for p in out_dir.glob('*.pkl')]),\n",
    "    }\n",
    "    with open(out_dir / \"manifest.json\", \"w\") as mf:\n",
    "        json.dump(manifest, mf, indent=2)\n",
    "\n",
    "print(\"\\nâœ… All balanced splits saved to:\", DEST_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c846a53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "304",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
