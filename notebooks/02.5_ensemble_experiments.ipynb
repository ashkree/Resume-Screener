{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8169ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70956af3",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c1f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def load_datasets(data_root: str | Path = \"data\",\n",
    "                  tasks: tuple[str, ...] = (\"binary\", \"multiclass\"),\n",
    "                  splits: tuple[str, ...] = (\"train\", \"val\", \"test\")) -> dict:\n",
    "\n",
    "    data_root = Path(data_root)\n",
    "    datasets  = {}\n",
    "\n",
    "    for task in tasks:\n",
    "        task_dir     = data_root / task\n",
    "        task_dict    = {}\n",
    "\n",
    "        for split in splits:\n",
    "            split_dict = {}\n",
    "            for kind in (\"X\", \"y\"):\n",
    "                file_path = task_dir / f\"{kind}_{split}.pkl\"\n",
    "                split_dict[kind] = pd.read_pickle(file_path)\n",
    "            task_dict[split] = split_dict\n",
    "\n",
    "        datasets[task] = task_dict\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8999d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Literal\n",
    "import pandas as pd\n",
    "\n",
    "def load_split(\n",
    "    preprocessing_type: Literal[\"cleaned_only\", \"full_process\"],\n",
    "    sampling_method: Literal[\"undersampled\", \"oversampled\"],\n",
    "    classification_type: Literal[\"binary\", \"multiclass\"]\n",
    ") -> Tuple[\n",
    "    Tuple[pd.DataFrame, pd.Series],  # train: (X_train, y_train)\n",
    "    Tuple[pd.DataFrame, pd.Series],  # val: (X_val, y_val)\n",
    "    Tuple[pd.DataFrame, pd.Series]   # test: (X_test, y_test)\n",
    "]:\n",
    "    \"\"\"\n",
    "    Load different types of splits from the data\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_type: must be \"cleaned_only\" or \"full_process\"\n",
    "        sampling_method: must be \"undersampled\" or \"oversampled\"\n",
    "        classification_type: must be \"binary\" or \"multiclass\"\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train, val, test) splits, where each split is (X, y)\n",
    "        - train: (X_train, y_train)\n",
    "        - val: (X_val, y_val)  \n",
    "        - test: (X_test, y_test)\n",
    "    \"\"\"\n",
    "    dataset = load_datasets(\n",
    "        f\"../data/{preprocessing_type}/{sampling_method}\")[classification_type]\n",
    "    split_names = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "    return tuple([(lambda split: (dataset[split][\"X\"], dataset[split][\"y\"]))(split) for split in split_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ac5e9",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a67f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(X):\n",
    "    X = X.copy()\n",
    "\n",
    "    combined = X[\"resume_text\"].astype(\n",
    "        str) + \" [SEP] \" + X[\"job_description_text\"].astype(str)\n",
    "\n",
    "    return combined.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ExperimentManager, Experiment\n",
    "\n",
    "baseline_manager = ExperimentManager(f\"../runs/ensembles/baselines/\", [\"Fit\", \"Not Fit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ebac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = load_split(preprocessing_type=\"cleaned_only\", sampling_method=\"undersampled\", classification_type=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cec0d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c94b8",
   "metadata": {},
   "source": [
    "## Experiment 1: Bagging vs Stacking\n",
    "\n",
    "### Experiment Summary\n",
    "\n",
    "This experiment was done to check the potential of Bagging vs Stacking. Stacking classifier with logistic regression meta learner (64.12%) outperforms bagging classifier (60.44%). Stack method will be used for succeeding experiemnts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b90027ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiment: SV ensemble classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6044\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6022\n",
      "   Micro F1:     0.6044\n",
      "   Weighted F1:  0.6022\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6068  R: 0.6044\n",
      "   Micro    - P: 0.6044  R: 0.6044\n",
      "   Weighted - P: 0.6068  R: 0.6044\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5909     0.6791     0.6319        857\n",
      "   Not Fit              0.6228     0.5298     0.5725        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6068     0.6044     0.6022       1714\n",
      "   weighted avg         0.6068     0.6044     0.6022       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           582      275 \n",
      "   Not Fit       403      454 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'SV ensemble classifier' completed and logged.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.ExperimentManger.Experiment at 0x303800c20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def pipeline_factory(params):\n",
    "\n",
    "    clf_lr = LogisticRegression(random_state=SEED)\n",
    "    clf_rf = RandomForestClassifier(random_state=SEED)\n",
    "    clf_nb = BernoulliNB()\n",
    "\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', clf_lr),\n",
    "            ('nb', clf_nb),\n",
    "            ('rf', clf_rf)\n",
    "        ],\n",
    "        voting=\"soft\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', voting_clf)  \n",
    "    ])\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=f\"SV ensemble classifier\",\n",
    "    description=f\"Soft Voting Ensemble Model Classifier\",\n",
    "    pipeline_factory=pipeline_factory\n",
    ")\n",
    "\n",
    "baseline_manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30d5c1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiment: LogReg meta stack ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6412\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6412\n",
      "   Micro F1:     0.6412\n",
      "   Weighted F1:  0.6412\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6412  R: 0.6412\n",
      "   Micro    - P: 0.6412  R: 0.6412\n",
      "   Weighted - P: 0.6412  R: 0.6412\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6391     0.6488     0.6439        857\n",
      "   Not Fit              0.6434     0.6336     0.6384        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6412     0.6412     0.6412       1714\n",
      "   weighted avg         0.6412     0.6412     0.6412       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           556      301 \n",
      "   Not Fit       314      543 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'LogReg meta stack' completed and logged.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.ExperimentManger.Experiment at 0x303efbe00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "def pipeline_factory(params):\n",
    "\n",
    "    clf_lr = LogisticRegression(random_state=SEED)\n",
    "    clf_rf = RandomForestClassifier(random_state=SEED)\n",
    "    clf_nb = BernoulliNB()\n",
    "\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', clf_lr),\n",
    "            ('nb', clf_nb),\n",
    "            ('rf', clf_rf)\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(random_state=42),\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', stacking_clf)\n",
    "    ])\n",
    "\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=f\"LogReg meta stack\",\n",
    "    description=f\"Stack ensemble classifier with LogisticRegression classifier\",\n",
    "    pipeline_factory=pipeline_factory\n",
    ")\n",
    "\n",
    "baseline_manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f95bb3",
   "metadata": {},
   "source": [
    "## Experiment 2: Meta learner comparisons for stacked ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3314c",
   "metadata": {},
   "source": [
    "- [ ] Random Forest\n",
    "- [ ] XGBoost\n",
    "- [ ] GradientBoostClassifier\n",
    "- [ ] Explainable Boosting Machine (BIG FUCKING MAYBE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd3052",
   "metadata": {},
   "source": [
    "### Random Forest meta learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df5829d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiment: Random forest meta stack ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6074\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6069\n",
      "   Micro F1:     0.6074\n",
      "   Weighted F1:  0.6069\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6079  R: 0.6074\n",
      "   Micro    - P: 0.6074  R: 0.6074\n",
      "   Weighted - P: 0.6079  R: 0.6074\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6004     0.6418     0.6204        857\n",
      "   Not Fit              0.6153     0.5729     0.5934        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6079     0.6074     0.6069       1714\n",
      "   weighted avg         0.6079     0.6074     0.6069       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           550      307 \n",
      "   Not Fit       366      491 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Random forest meta stack' completed and logged.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.ExperimentManger.Experiment at 0x303e79cd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pipeline_factory(params):\n",
    "\n",
    "    clf_lr = LogisticRegression(random_state=SEED)\n",
    "    clf_rf = RandomForestClassifier(random_state=SEED)\n",
    "    clf_nb = BernoulliNB()\n",
    "\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', clf_lr),\n",
    "            ('nb', clf_nb),\n",
    "            ('rf', clf_rf)\n",
    "        ],\n",
    "        final_estimator=RandomForestClassifier(random_state=42),\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', stacking_clf)\n",
    "    ])\n",
    "\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=f\"Random forest meta stack\",\n",
    "    description=f\"Stack ensemble classifier with random forest classifier\",\n",
    "    pipeline_factory=pipeline_factory\n",
    ")\n",
    "\n",
    "baseline_manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d9f3b",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d38ec1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiment: XGBoost meta stack ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:24:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"metric\", \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5887\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5886\n",
      "   Micro F1:     0.5887\n",
      "   Weighted F1:  0.5886\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5887  R: 0.5887\n",
      "   Micro    - P: 0.5887  R: 0.5887\n",
      "   Weighted - P: 0.5887  R: 0.5887\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5905     0.5788     0.5846        857\n",
      "   Not Fit              0.5870     0.5986     0.5927        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5887     0.5887     0.5886       1714\n",
      "   weighted avg         0.5887     0.5887     0.5886       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           496      361 \n",
      "   Not Fit       344      513 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'XGBoost meta stack' completed and logged.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.ExperimentManger.Experiment at 0x3062ce300>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def pipeline_factory(params):\n",
    "\n",
    "    clf_lr = LogisticRegression(random_state=SEED)\n",
    "    clf_rf = RandomForestClassifier(random_state=SEED)\n",
    "    clf_nb = BernoulliNB()\n",
    "\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', clf_lr),\n",
    "            ('nb', clf_nb),\n",
    "            ('rf', clf_rf)\n",
    "        ],\n",
    "        final_estimator=XGBClassifier(use_label_encoder = False, metric = \"logloss\"),\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', stacking_clf)\n",
    "    ])\n",
    "\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=f\"XGBoost meta stack\",\n",
    "    description=f\"Stack ensemble classifier with XGBoost classifier\",\n",
    "    pipeline_factory=pipeline_factory\n",
    ")\n",
    "\n",
    "baseline_manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e670aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "304",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
