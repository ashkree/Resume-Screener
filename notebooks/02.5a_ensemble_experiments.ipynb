{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8169ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48471841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import multiprocessing\n",
    "warnings.filterwarnings(\"ignore\", category=ResourceWarning)\n",
    "\n",
    "# Also suppress multiprocessing warnings\n",
    "import sys\n",
    "import os\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore::ResourceWarning'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70956af3",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c1f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def load_datasets(data_root: str | Path = \"data\",\n",
    "                  tasks: tuple[str, ...] = (\"binary\", \"multiclass\"),\n",
    "                  splits: tuple[str, ...] = (\"train\", \"val\", \"test\")) -> dict:\n",
    "\n",
    "    data_root = Path(data_root)\n",
    "    datasets  = {}\n",
    "\n",
    "    for task in tasks:\n",
    "        task_dir     = data_root / task\n",
    "        task_dict    = {}\n",
    "\n",
    "        for split in splits:\n",
    "            split_dict = {}\n",
    "            for kind in (\"X\", \"y\"):\n",
    "                file_path = task_dir / f\"{kind}_{split}.pkl\"\n",
    "                split_dict[kind] = pd.read_pickle(file_path)\n",
    "            task_dict[split] = split_dict\n",
    "\n",
    "        datasets[task] = task_dict\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8999d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Literal\n",
    "import pandas as pd\n",
    "\n",
    "def load_split(\n",
    "    preprocessing_type: Literal[\"cleaned_only\", \"full_process\"],\n",
    "    sampling_method: Literal[\"undersampled\", \"oversampled\"],\n",
    "    classification_type: Literal[\"binary\", \"multiclass\"]\n",
    ") -> Tuple[\n",
    "    Tuple[pd.DataFrame, pd.Series],  # train: (X_train, y_train)\n",
    "    Tuple[pd.DataFrame, pd.Series],  # val: (X_val, y_val)\n",
    "    Tuple[pd.DataFrame, pd.Series]   # test: (X_test, y_test)\n",
    "]:\n",
    "    \"\"\"\n",
    "    Load different types of splits from the data\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_type: must be \"cleaned_only\" or \"full_process\"\n",
    "        sampling_method: must be \"undersampled\" or \"oversampled\"\n",
    "        classification_type: must be \"binary\" or \"multiclass\"\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train, val, test) splits, where each split is (X, y)\n",
    "        - train: (X_train, y_train)\n",
    "        - val: (X_val, y_val)  \n",
    "        - test: (X_test, y_test)\n",
    "    \"\"\"\n",
    "    dataset = load_datasets(\n",
    "        f\"../data/{preprocessing_type}/{sampling_method}\")[classification_type]\n",
    "    split_names = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "    return tuple([(lambda split: (dataset[split][\"X\"], dataset[split][\"y\"]))(split) for split in split_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ac5e9",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a67f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(X):\n",
    "    X = X.copy()\n",
    "\n",
    "    combined = X[\"resume_text\"].astype(\n",
    "        str) + \" [SEP] \" + X[\"job_description_text\"].astype(str)\n",
    "\n",
    "    return combined.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ebac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = load_split(preprocessing_type=\"cleaned_only\", sampling_method=\"undersampled\", classification_type=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cec0d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fca1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ExperimentManager, Experiment\n",
    "\n",
    "method_manager = ExperimentManager(f\"../runs/ensembles/\", [\"Fit\", \"Not Fit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c94b8",
   "metadata": {},
   "source": [
    "## Experiment 1: Bagging vs Stacking\n",
    "\n",
    "### Experiment Summary\n",
    "\n",
    "This experiment was done to check the potential of Bagging vs Stacking. Stacking classifier with logistic regression meta learner (64.12%) outperforms bagging classifier (60.44%). Stack method will be used for succeeding experiemnts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b90027ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiment: HV ensemble classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6167\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6158\n",
      "   Micro F1:     0.6167\n",
      "   Weighted F1:  0.6158\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6177  R: 0.6167\n",
      "   Micro    - P: 0.6167  R: 0.6167\n",
      "   Weighted - P: 0.6177  R: 0.6167\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6066     0.6639     0.6340        857\n",
      "   Not Fit              0.6289     0.5694     0.5977        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6177     0.6167     0.6158       1714\n",
      "   weighted avg         0.6177     0.6167     0.6158       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           569      288 \n",
      "   Not Fit       369      488 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'HV ensemble classifier' completed and logged.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.ExperimentManger.Experiment at 0x7f0d980660f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def pipeline_factory(params):\n",
    "\n",
    "    clf_lr = LogisticRegression(random_state=SEED)\n",
    "    clf_rf = RandomForestClassifier(random_state=SEED)\n",
    "    clf_nb = BernoulliNB()\n",
    "\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', clf_lr),\n",
    "            ('nb', clf_nb),\n",
    "            ('rf', clf_rf)\n",
    "        ],\n",
    "        # using hard here since Ridge does not have predict_proba\n",
    "        voting=\"hard\",\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', voting_clf)  \n",
    "    ])\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=f\"HV ensemble classifier\",\n",
    "    description=f\"Hard Voting Ensemble Model Classifier\",\n",
    "    pipeline_factory=pipeline_factory\n",
    ")\n",
    "\n",
    "method_manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30d5c1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiment: LogReg meta stack ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6394\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6394\n",
      "   Micro F1:     0.6394\n",
      "   Weighted F1:  0.6394\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6395  R: 0.6394\n",
      "   Micro    - P: 0.6394  R: 0.6394\n",
      "   Weighted - P: 0.6395  R: 0.6394\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6366     0.6499     0.6432        857\n",
      "   Not Fit              0.6424     0.6289     0.6356        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6395     0.6394     0.6394       1714\n",
      "   weighted avg         0.6395     0.6394     0.6394       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           557      300 \n",
      "   Not Fit       318      539 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'LogReg meta stack' completed and logged.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.ExperimentManger.Experiment at 0x7f0c45f4f110>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "def pipeline_factory(params):\n",
    "\n",
    "    clf_lr = LogisticRegression(random_state=SEED)\n",
    "    clf_rf = RandomForestClassifier(random_state=SEED)\n",
    "    clf_nb = BernoulliNB()\n",
    "\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', clf_lr),\n",
    "            ('nb', clf_nb),\n",
    "            ('rf', clf_rf)\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(random_state=42),\n",
    "        cv=5,\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', stacking_clf)\n",
    "    ])\n",
    "\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=f\"LogReg meta stack\",\n",
    "    description=f\"Stack ensemble classifier with LogisticRegression classifier\",\n",
    "    pipeline_factory=pipeline_factory\n",
    ")\n",
    "\n",
    "method_manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db3e3504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "HV ensemble classifier         0.6167       âœ… Completed\n",
      "LogReg meta stack              0.6394       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: bag_vs_stack.csv\n"
     ]
    }
   ],
   "source": [
    "method_manager.compare_experiments()\n",
    "\n",
    "filename = \"bag_vs_stack.csv\"\n",
    "dir = \"../experiment_summaries/ensemble\"\n",
    "\n",
    "method_manager.export_experiment_summary(dir, filename)\n",
    "method_manager.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f95bb3",
   "metadata": {},
   "source": [
    "## Experiment 2: Meta learner comparisons for stacked ensembles\n",
    "\n",
    "- [X] Random Forest\n",
    "- [X] XGBoost\n",
    "- [X] Explainable Boosting Machine\n",
    "- [X] RidgeClassifier\n",
    "\n",
    "### Experiment Summary\n",
    "Overall Logistic Regression remains the best at 63.94%, however, explainable boosting machine and ridge classifer are clost at 63.01% and 63.77% respectively. Thus future experiments will involve all three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3129ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ExperimentManager, Experiment\n",
    "\n",
    "meta_learner_manager = ExperimentManager(f\"../runs/ensembles/\", [\"Fit\", \"Not Fit\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91237f4b",
   "metadata": {},
   "source": [
    "### LogReg Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b40b8867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiment: LogReg meta stack ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6394\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6394\n",
      "   Micro F1:     0.6394\n",
      "   Weighted F1:  0.6394\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6395  R: 0.6394\n",
      "   Micro    - P: 0.6394  R: 0.6394\n",
      "   Weighted - P: 0.6395  R: 0.6394\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6366     0.6499     0.6432        857\n",
      "   Not Fit              0.6424     0.6289     0.6356        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6395     0.6394     0.6394       1714\n",
      "   weighted avg         0.6395     0.6394     0.6394       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           557      300 \n",
      "   Not Fit       318      539 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'LogReg meta stack' completed and logged.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.ExperimentManger.Experiment at 0x7f0c45c5df70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "def pipeline_factory(params):\n",
    "\n",
    "    clf_lr = LogisticRegression(random_state=SEED)\n",
    "    clf_rf = RandomForestClassifier(random_state=SEED)\n",
    "    clf_nb = BernoulliNB()\n",
    "\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', clf_lr),\n",
    "            ('nb', clf_nb),\n",
    "            ('rf', clf_rf)\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(random_state=42),\n",
    "        cv=5,\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', stacking_clf)\n",
    "    ])\n",
    "\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=f\"LogReg meta stack\",\n",
    "    description=f\"Stack ensemble classifier with LogisticRegression classifier\",\n",
    "    pipeline_factory=pipeline_factory\n",
    ")\n",
    "\n",
    "meta_learner_manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd392fa",
   "metadata": {},
   "source": [
    "### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d0967d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiment: Ridge meta stack ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6377\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6376\n",
      "   Micro F1:     0.6377\n",
      "   Weighted F1:  0.6376\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6378  R: 0.6377\n",
      "   Micro    - P: 0.6377  R: 0.6377\n",
      "   Weighted - P: 0.6378  R: 0.6377\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6344     0.6499     0.6421        857\n",
      "   Not Fit              0.6411     0.6254     0.6332        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6378     0.6377     0.6376       1714\n",
      "   weighted avg         0.6378     0.6377     0.6376       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           557      300 \n",
      "   Not Fit       321      536 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Ridge meta stack' completed and logged.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.ExperimentManger.Experiment at 0x7f0c472d03e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "def pipeline_factory(params):\n",
    "\n",
    "    clf_lr = LogisticRegression(random_state=SEED)\n",
    "    clf_rf = RandomForestClassifier(random_state=SEED)\n",
    "    clf_nb = BernoulliNB()\n",
    "\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', clf_lr),\n",
    "            ('nb', clf_nb),\n",
    "            ('rf', clf_rf)\n",
    "        ],\n",
    "        final_estimator=RidgeClassifier(random_state=SEED),\n",
    "        cv=5,\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', stacking_clf)\n",
    "    ])\n",
    "\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=f\"Ridge meta stack\",\n",
    "    description=f\"Stack ensemble classifier with Ridge classifier\",\n",
    "    pipeline_factory=pipeline_factory\n",
    ")\n",
    "\n",
    "meta_learner_manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd3052",
   "metadata": {},
   "source": [
    "### Random Forest meta learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5829d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiment: Random forest meta stack ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6126\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6116\n",
      "   Micro F1:     0.6126\n",
      "   Weighted F1:  0.6116\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6137  R: 0.6126\n",
      "   Micro    - P: 0.6126  R: 0.6126\n",
      "   Weighted - P: 0.6137  R: 0.6126\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6023     0.6628     0.6311        857\n",
      "   Not Fit              0.6252     0.5624     0.5921        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6137     0.6126     0.6116       1714\n",
      "   weighted avg         0.6137     0.6126     0.6116       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           568      289 \n",
      "   Not Fit       375      482 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Random forest meta stack' completed and logged.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.ExperimentManger.Experiment at 0x7f0c45f3e420>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pipeline_factory(params):\n",
    "\n",
    "    clf_lr = LogisticRegression(random_state=SEED)\n",
    "    clf_rf = RandomForestClassifier(random_state=SEED)\n",
    "    clf_nb = BernoulliNB()\n",
    "\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', clf_lr),\n",
    "            ('nb', clf_nb),\n",
    "            ('rf', clf_rf)\n",
    "        ],\n",
    "        final_estimator=RandomForestClassifier(random_state=42),\n",
    "        cv=5,\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', stacking_clf)\n",
    "    ])\n",
    "\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=f\"Random forest meta stack\",\n",
    "    description=f\"Stack ensemble classifier with random forest classifier\",\n",
    "    pipeline_factory=pipeline_factory\n",
    ")\n",
    "\n",
    "meta_learner_manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f045e06",
   "metadata": {},
   "source": [
    "### Explainable Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e670aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Experiment: EBM meta stack ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6301\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6301\n",
      "   Micro F1:     0.6301\n",
      "   Weighted F1:  0.6301\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6301  R: 0.6301\n",
      "   Micro    - P: 0.6301  R: 0.6301\n",
      "   Weighted - P: 0.6301  R: 0.6301\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6286     0.6359     0.6323        857\n",
      "   Not Fit              0.6316     0.6243     0.6279        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6301     0.6301     0.6301       1714\n",
      "   weighted avg         0.6301     0.6301     0.6301       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           545      312 \n",
      "   Not Fit       322      535 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'EBM meta stack' completed and logged.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.ExperimentManger.Experiment at 0x7f0c472e0bf0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "def pipeline_factory(params):\n",
    "\n",
    "    clf_lr = LogisticRegression(random_state=SEED)\n",
    "    clf_rf = RandomForestClassifier(random_state=SEED)\n",
    "    clf_nb = BernoulliNB()\n",
    "\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', clf_lr),\n",
    "            ('nb', clf_nb),\n",
    "            ('rf', clf_rf)\n",
    "        ],\n",
    "        final_estimator=ExplainableBoostingClassifier(random_state=SEED),\n",
    "        cv=5,\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', stacking_clf)\n",
    "    ])\n",
    "\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=f\"EBM meta stack\",\n",
    "    description=f\"Stack ensemble classifier with EBM classifier\",\n",
    "    pipeline_factory=pipeline_factory\n",
    ")\n",
    "\n",
    "meta_learner_manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afb51a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "LogReg meta stack              0.6394       âœ… Completed\n",
      "Ridge meta stack               0.6377       âœ… Completed\n",
      "Random forest meta stack       0.6126       âœ… Completed\n",
      "EBM meta stack                 0.6301       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: meta_learner_comparisons.csv\n"
     ]
    }
   ],
   "source": [
    "meta_learner_manager.compare_experiments()\n",
    "\n",
    "filename = \"meta_learner_comparisons.csv\"\n",
    "dir = \"../experiment_summaries/ensemble\"\n",
    "\n",
    "meta_learner_manager.export_experiment_summary(dir, filename)\n",
    "meta_learner_manager.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "304",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
