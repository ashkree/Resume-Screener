{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f772aba6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98a2da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa609bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e2f8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG = 42\n",
    "np.random.seed(RNG)\n",
    "random.seed(RNG)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(RNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17715201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(data_root: str | Path = \"data\",\n",
    "                  tasks: tuple[str, ...] = (\"binary\", \"multiclass\"),\n",
    "                  splits: tuple[str, ...] = (\"train\", \"val\", \"test\")) -> dict:\n",
    "\n",
    "    data_root = Path(data_root)\n",
    "    datasets  = {}\n",
    "\n",
    "    for task in tasks:\n",
    "        task_dir     = data_root / task\n",
    "        task_dict    = {}\n",
    "\n",
    "        for split in splits:\n",
    "            split_dict = {}\n",
    "            for kind in (\"X\", \"y\"):\n",
    "                file_path = task_dir / f\"{kind}_{split}.pkl\"\n",
    "                split_dict[kind] = pd.read_pickle(file_path)\n",
    "            task_dict[split] = split_dict\n",
    "\n",
    "        datasets[task] = task_dict\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "592705e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Literal\n",
    "import pandas as pd\n",
    "\n",
    "def load_split(\n",
    "    preprocessing_type: Literal[\"cleaned_only\", \"full_process\"], \n",
    "    sampling_method: Literal[\"undersampled\", \"oversampled\"],\n",
    "    classification_type: Literal[\"binary\", \"multiclass\"] \n",
    ") -> Tuple[\n",
    "    Tuple[pd.DataFrame, pd.Series],  # train: (X_train, y_train)\n",
    "    Tuple[pd.DataFrame, pd.Series],  # val: (X_val, y_val)\n",
    "    Tuple[pd.DataFrame, pd.Series]   # test: (X_test, y_test)\n",
    "]:\n",
    "    \"\"\"\n",
    "    Load different types of splits from the data\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_type: must be \"cleaned_only\" or \"full_process\"\n",
    "        sampling_method: must be \"undersampled\" or \"oversampled\"\n",
    "        classification_type: must be \"binary\" or \"multiclass\"\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train, val, test) splits, where each split is (X, y)\n",
    "        - train: (X_train, y_train)\n",
    "        - val: (X_val, y_val)  \n",
    "        - test: (X_test, y_test)\n",
    "    \"\"\"\n",
    "    dataset = load_datasets(f\"../data/{preprocessing_type}/{sampling_method}\")[classification_type]\n",
    "    split_names = [\"train\", \"val\", \"test\"]\n",
    "    \n",
    "    return tuple([(lambda split: (dataset[split][\"X\"], dataset[split][\"y\"]))(split) for split in split_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c40c6",
   "metadata": {},
   "source": [
    "# Baseline Comparisons \n",
    "\n",
    "Goal is to identify which models to use for ensemble as well as see which dataset would provide better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4922ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(X):\n",
    "    X = X.copy() \n",
    "\n",
    "    combined = X[\"resume_text\"].astype(str) + \" [SEP] \" + X[\"job_description_text\"].astype(str)\n",
    "\n",
    "    return combined.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "35d75bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline components\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb81266",
   "metadata": {},
   "source": [
    "## Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2d24cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ExperimentManager, Experiment\n",
    "\n",
    "manager = ExperimentManager(f\"../runs/binary/baselines/\", [\"Fit\", \"Not Fit\"])\n",
    "CLASSIFICATION_TYPE = \"binary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24afa76",
   "metadata": {},
   "source": [
    "### Linear Models\n",
    "\n",
    "RidgeClassifier performs the best. Unclear if stop word removal and lemmatization are beneficial. Undersampling performs the best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e278f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        penalty='l2',\n",
    "        C=1.0,\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    \"Ridge\": RidgeClassifier(\n",
    "        alpha=1.0, \n",
    "        class_weight='balanced', \n",
    "        random_state=42\n",
    "    ),\n",
    "    \n",
    "    \"LinearSVC\": LinearSVC(\n",
    "        C=1.0,\n",
    "        class_weight='balanced',\n",
    "        dual=False,\n",
    "        random_state=42,\n",
    "        max_iter=2000\n",
    "    )\n",
    "}\n",
    "\n",
    "MODEL_FAMILY = \"linear_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "04ed3d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Logistic Regression classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6004\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6000\n",
      "   Micro F1:     0.6004\n",
      "   Weighted F1:  0.6000\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6007  R: 0.6004\n",
      "   Micro    - P: 0.6004  R: 0.6004\n",
      "   Weighted - P: 0.6007  R: 0.6004\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5951     0.6278     0.6110        857\n",
      "   Not Fit              0.6062     0.5729     0.5891        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6007     0.6004     0.6000       1714\n",
      "   weighted avg         0.6007     0.6004     0.6000       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           538      319 \n",
      "   Not Fit       366      491 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Logistic Regression classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Ridge classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6009\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6006\n",
      "   Micro F1:     0.6009\n",
      "   Weighted F1:  0.6006\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6013  R: 0.6009\n",
      "   Micro    - P: 0.6009  R: 0.6009\n",
      "   Weighted - P: 0.6013  R: 0.6009\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5952     0.6313     0.6127        857\n",
      "   Not Fit              0.6075     0.5706     0.5884        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6013     0.6009     0.6006       1714\n",
      "   weighted avg         0.6013     0.6009     0.6006       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           541      316 \n",
      "   Not Fit       368      489 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Ridge classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: LinearSVC classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5980\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5979\n",
      "   Micro F1:     0.5980\n",
      "   Weighted F1:  0.5979\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5981  R: 0.5980\n",
      "   Micro    - P: 0.5980  R: 0.5980\n",
      "   Weighted - P: 0.5981  R: 0.5980\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5946     0.6161     0.6052        857\n",
      "   Not Fit              0.6017     0.5799     0.5906        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5981     0.5980     0.5979       1714\n",
      "   weighted avg         0.5981     0.5980     0.5979       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           528      329 \n",
      "   Not Fit       360      497 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'LinearSVC classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"cleaned_only\"\n",
    "SAMPLING_METHOD = \"undersampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in linear_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8b61d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Logistic Regression classifier 0.6004       âœ… Completed\n",
      "Ridge classifier               0.6009       âœ… Completed\n",
      "LinearSVC classifier           0.5980       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_cleaned_only_undersampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "708404d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Logistic Regression classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5831\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5827\n",
      "   Micro F1:     0.5831\n",
      "   Weighted F1:  0.5827\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5835  R: 0.5831\n",
      "   Micro    - P: 0.5831  R: 0.5831\n",
      "   Weighted - P: 0.5835  R: 0.5831\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5783     0.6142     0.5957        902\n",
      "   Not Fit              0.5887     0.5521     0.5698        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5835     0.5831     0.5827       1804\n",
      "   weighted avg         0.5835     0.5831     0.5827       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           554      348 \n",
      "   Not Fit       404      498 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Logistic Regression classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Ridge classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5804\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5796\n",
      "   Micro F1:     0.5804\n",
      "   Weighted F1:  0.5796\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5810  R: 0.5804\n",
      "   Micro    - P: 0.5804  R: 0.5804\n",
      "   Weighted - P: 0.5810  R: 0.5804\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5739     0.6242     0.5980        902\n",
      "   Not Fit              0.5881     0.5366     0.5612        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5810     0.5804     0.5796       1804\n",
      "   weighted avg         0.5810     0.5804     0.5796       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           563      339 \n",
      "   Not Fit       418      484 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Ridge classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: LinearSVC classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5765\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5757\n",
      "   Micro F1:     0.5765\n",
      "   Weighted F1:  0.5757\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5770  R: 0.5765\n",
      "   Micro    - P: 0.5765  R: 0.5765\n",
      "   Weighted - P: 0.5770  R: 0.5765\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5706     0.6186     0.5936        902\n",
      "   Not Fit              0.5835     0.5344     0.5579        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5770     0.5765     0.5757       1804\n",
      "   weighted avg         0.5770     0.5765     0.5757       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           558      344 \n",
      "   Not Fit       420      482 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'LinearSVC classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PREPROCESSING_TYPE = \"full_process\"\n",
    "SAMPLING_METHOD = \"undersampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in linear_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b16ca2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Logistic Regression classifier 0.5831       âœ… Completed\n",
      "Ridge classifier               0.5804       âœ… Completed\n",
      "LinearSVC classifier           0.5765       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_full_process_undersampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f9a7f917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Logistic Regression classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5898\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5896\n",
      "   Micro F1:     0.5898\n",
      "   Weighted F1:  0.5896\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5900  R: 0.5898\n",
      "   Micro    - P: 0.5898  R: 0.5898\n",
      "   Weighted - P: 0.5900  R: 0.5898\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5858     0.6131     0.5991        902\n",
      "   Not Fit              0.5942     0.5665     0.5800        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5900     0.5898     0.5896       1804\n",
      "   weighted avg         0.5900     0.5898     0.5896       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           553      349 \n",
      "   Not Fit       391      511 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Logistic Regression classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Ridge classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5931\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5922\n",
      "   Micro F1:     0.5931\n",
      "   Weighted F1:  0.5922\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5939  R: 0.5931\n",
      "   Micro    - P: 0.5931  R: 0.5931\n",
      "   Weighted - P: 0.5939  R: 0.5931\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5852     0.6397     0.6112        902\n",
      "   Not Fit              0.6027     0.5466     0.5733        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5939     0.5931     0.5922       1804\n",
      "   weighted avg         0.5939     0.5931     0.5922       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           577      325 \n",
      "   Not Fit       409      493 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Ridge classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: LinearSVC classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5759\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5748\n",
      "   Micro F1:     0.5759\n",
      "   Weighted F1:  0.5748\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5768  R: 0.5759\n",
      "   Micro    - P: 0.5759  R: 0.5759\n",
      "   Weighted - P: 0.5768  R: 0.5759\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5687     0.6286     0.5972        902\n",
      "   Not Fit              0.5849     0.5233     0.5524        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5768     0.5759     0.5748       1804\n",
      "   weighted avg         0.5768     0.5759     0.5748       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           567      335 \n",
      "   Not Fit       430      472 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'LinearSVC classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"cleaned_only\"\n",
    "SAMPLING_METHOD = \"oversampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in linear_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c0bba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Logistic Regression classifier 0.5898       âœ… Completed\n",
      "Ridge classifier               0.5931       âœ… Completed\n",
      "LinearSVC classifier           0.5759       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_cleaned_only_oversampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "567b612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Logistic Regression classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5898\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5896\n",
      "   Micro F1:     0.5898\n",
      "   Weighted F1:  0.5896\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5900  R: 0.5898\n",
      "   Micro    - P: 0.5898  R: 0.5898\n",
      "   Weighted - P: 0.5900  R: 0.5898\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5858     0.6131     0.5991        902\n",
      "   Not Fit              0.5942     0.5665     0.5800        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5900     0.5898     0.5896       1804\n",
      "   weighted avg         0.5900     0.5898     0.5896       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           553      349 \n",
      "   Not Fit       391      511 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Logistic Regression classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Ridge classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5931\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5922\n",
      "   Micro F1:     0.5931\n",
      "   Weighted F1:  0.5922\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5939  R: 0.5931\n",
      "   Micro    - P: 0.5931  R: 0.5931\n",
      "   Weighted - P: 0.5939  R: 0.5931\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5852     0.6397     0.6112        902\n",
      "   Not Fit              0.6027     0.5466     0.5733        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5939     0.5931     0.5922       1804\n",
      "   weighted avg         0.5939     0.5931     0.5922       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           577      325 \n",
      "   Not Fit       409      493 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Ridge classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: LinearSVC classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5759\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5748\n",
      "   Micro F1:     0.5759\n",
      "   Weighted F1:  0.5748\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5768  R: 0.5759\n",
      "   Micro    - P: 0.5759  R: 0.5759\n",
      "   Weighted - P: 0.5768  R: 0.5759\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5687     0.6286     0.5972        902\n",
      "   Not Fit              0.5849     0.5233     0.5524        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5768     0.5759     0.5748       1804\n",
      "   weighted avg         0.5768     0.5759     0.5748       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           567      335 \n",
      "   Not Fit       430      472 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'LinearSVC classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"full_process\"\n",
    "SAMPLING_METHOD = \"oversampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in linear_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "79d3bfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Logistic Regression classifier 0.5898       âœ… Completed\n",
      "Ridge classifier               0.5931       âœ… Completed\n",
      "LinearSVC classifier           0.5759       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_full_process_oversampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af25c593",
   "metadata": {},
   "source": [
    "### Tree Models\n",
    "\n",
    "RidgeClassifier performs the best. Unclear if stop word removal and lemmatization are beneficial. Undersampling performs the best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d0fa39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "tree_models = {\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    \"ExtraTrees\": ExtraTreesClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        max_depth=None,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2\n",
    "    )\n",
    "}\n",
    "\n",
    "MODEL_FAMILY = \"tree_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9333d6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Random Forest classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6476\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6475\n",
      "   Micro F1:     0.6476\n",
      "   Weighted F1:  0.6475\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6478  R: 0.6476\n",
      "   Micro    - P: 0.6476  R: 0.6476\n",
      "   Weighted - P: 0.6478  R: 0.6476\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6420     0.6674     0.6545        857\n",
      "   Not Fit              0.6537     0.6278     0.6405        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6478     0.6476     0.6475       1714\n",
      "   weighted avg         0.6478     0.6476     0.6475       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           572      285 \n",
      "   Not Fit       319      538 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Random Forest classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ExtraTrees classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6342\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6341\n",
      "   Micro F1:     0.6342\n",
      "   Weighted F1:  0.6341\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6343  R: 0.6342\n",
      "   Micro    - P: 0.6342  R: 0.6342\n",
      "   Weighted - P: 0.6343  R: 0.6342\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6298     0.6511     0.6403        857\n",
      "   Not Fit              0.6389     0.6173     0.6279        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6343     0.6342     0.6341       1714\n",
      "   weighted avg         0.6343     0.6342     0.6341       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           558      299 \n",
      "   Not Fit       328      529 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ExtraTrees classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"cleaned_only\"\n",
    "SAMPLING_METHOD = \"undersampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in tree_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c0fde450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Random Forest classifier       0.6476       âœ… Completed\n",
      "ExtraTrees classifier          0.6342       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_cleaned_only_undersampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07344fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Random Forest classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6447\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6446\n",
      "   Micro F1:     0.6447\n",
      "   Weighted F1:  0.6446\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6448  R: 0.6447\n",
      "   Micro    - P: 0.6447  R: 0.6447\n",
      "   Weighted - P: 0.6448  R: 0.6447\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6411     0.6574     0.6492        902\n",
      "   Not Fit              0.6485     0.6319     0.6401        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6448     0.6447     0.6446       1804\n",
      "   weighted avg         0.6448     0.6447     0.6446       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           593      309 \n",
      "   Not Fit       332      570 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Random Forest classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ExtraTrees classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6253\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6250\n",
      "   Micro F1:     0.6253\n",
      "   Weighted F1:  0.6250\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6257  R: 0.6253\n",
      "   Micro    - P: 0.6253  R: 0.6253\n",
      "   Weighted - P: 0.6257  R: 0.6253\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6187     0.6530     0.6354        902\n",
      "   Not Fit              0.6326     0.5976     0.6146        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6257     0.6253     0.6250       1804\n",
      "   weighted avg         0.6257     0.6253     0.6250       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           589      313 \n",
      "   Not Fit       363      539 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ExtraTrees classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PREPROCESSING_TYPE = \"full_process\"\n",
    "SAMPLING_METHOD = \"undersampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in tree_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0ee5e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Random Forest classifier       0.6447       âœ… Completed\n",
      "ExtraTrees classifier          0.6253       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_full_process_undersampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cb29a34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Random Forest classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6341\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6341\n",
      "   Micro F1:     0.6341\n",
      "   Weighted F1:  0.6341\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6341  R: 0.6341\n",
      "   Micro    - P: 0.6341  R: 0.6341\n",
      "   Weighted - P: 0.6341  R: 0.6341\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6344     0.6330     0.6337        902\n",
      "   Not Fit              0.6338     0.6353     0.6346        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6341     0.6341     0.6341       1804\n",
      "   weighted avg         0.6341     0.6341     0.6341       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           571      331 \n",
      "   Not Fit       329      573 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Random Forest classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ExtraTrees classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6347\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6343\n",
      "   Micro F1:     0.6347\n",
      "   Weighted F1:  0.6343\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6353  R: 0.6347\n",
      "   Micro    - P: 0.6347  R: 0.6347\n",
      "   Weighted - P: 0.6353  R: 0.6347\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6262     0.6685     0.6466        902\n",
      "   Not Fit              0.6445     0.6009     0.6219        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6353     0.6347     0.6343       1804\n",
      "   weighted avg         0.6353     0.6347     0.6343       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           603      299 \n",
      "   Not Fit       360      542 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ExtraTrees classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"cleaned_only\"\n",
    "SAMPLING_METHOD = \"oversampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in tree_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "44a385b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Random Forest classifier       0.6341       âœ… Completed\n",
      "ExtraTrees classifier          0.6347       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_cleaned_only_oversampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d76c35bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Random Forest classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6341\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6341\n",
      "   Micro F1:     0.6341\n",
      "   Weighted F1:  0.6341\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6341  R: 0.6341\n",
      "   Micro    - P: 0.6341  R: 0.6341\n",
      "   Weighted - P: 0.6341  R: 0.6341\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6344     0.6330     0.6337        902\n",
      "   Not Fit              0.6338     0.6353     0.6346        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6341     0.6341     0.6341       1804\n",
      "   weighted avg         0.6341     0.6341     0.6341       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           571      331 \n",
      "   Not Fit       329      573 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Random Forest classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ExtraTrees classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6347\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6343\n",
      "   Micro F1:     0.6347\n",
      "   Weighted F1:  0.6343\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6353  R: 0.6347\n",
      "   Micro    - P: 0.6347  R: 0.6347\n",
      "   Weighted - P: 0.6353  R: 0.6347\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.6262     0.6685     0.6466        902\n",
      "   Not Fit              0.6445     0.6009     0.6219        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6353     0.6347     0.6343       1804\n",
      "   weighted avg         0.6353     0.6347     0.6343       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           603      299 \n",
      "   Not Fit       360      542 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ExtraTrees classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"full_process\"\n",
    "SAMPLING_METHOD = \"oversampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in tree_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2ad56792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Random Forest classifier       0.6341       âœ… Completed\n",
      "ExtraTrees classifier          0.6347       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_full_process_oversampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4cb6b9",
   "metadata": {},
   "source": [
    "### Naive Bayes Models\n",
    "\n",
    "RidgeClassifier performs the best. Unclear if stop word removal and lemmatization are beneficial. Undersampling performs the best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71cb2c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, ComplementNB\n",
    "\n",
    "naive_bayes_models = {\n",
    "    \"MultinomialNB\": MultinomialNB(\n",
    "        alpha=1.0,\n",
    "        fit_prior=True\n",
    "    ),\n",
    "    \n",
    "    \"BernoulliNB\": BernoulliNB(\n",
    "        alpha=1.0,\n",
    "        binarize=0.0,\n",
    "        fit_prior=True\n",
    "    ),\n",
    "    \n",
    "    \"ComplementNB\": ComplementNB(\n",
    "        alpha=1.0,\n",
    "        fit_prior=True,\n",
    "        norm=False\n",
    "    )\n",
    "}\n",
    "\n",
    "MODEL_FAMILY = \"naive_bayes_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9a8da2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: MultinomialNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5951\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5930\n",
      "   Micro F1:     0.5951\n",
      "   Weighted F1:  0.5930\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5971  R: 0.5951\n",
      "   Micro    - P: 0.5951  R: 0.5951\n",
      "   Weighted - P: 0.5971  R: 0.5951\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5832     0.6663     0.6220        857\n",
      "   Not Fit              0.6109     0.5239     0.5641        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5971     0.5951     0.5930       1714\n",
      "   weighted avg         0.5971     0.5951     0.5930       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           571      286 \n",
      "   Not Fit       408      449 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'MultinomialNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: BernoulliNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.6050\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.6027\n",
      "   Micro F1:     0.6050\n",
      "   Weighted F1:  0.6027\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.6075  R: 0.6050\n",
      "   Micro    - P: 0.6050  R: 0.6050\n",
      "   Weighted - P: 0.6075  R: 0.6050\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5911     0.6814     0.6331        857\n",
      "   Not Fit              0.6240     0.5286     0.5723        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.6075     0.6050     0.6027       1714\n",
      "   weighted avg         0.6075     0.6050     0.6027       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           584      273 \n",
      "   Not Fit       404      453 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'BernoulliNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ComplementNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,714\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5951\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5930\n",
      "   Micro F1:     0.5951\n",
      "   Weighted F1:  0.5930\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5971  R: 0.5951\n",
      "   Micro    - P: 0.5951  R: 0.5951\n",
      "   Weighted - P: 0.5971  R: 0.5951\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5832     0.6663     0.6220        857\n",
      "   Not Fit              0.6109     0.5239     0.5641        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5971     0.5951     0.5930       1714\n",
      "   weighted avg         0.5971     0.5951     0.5930       1714\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           571      286 \n",
      "   Not Fit       408      449 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ComplementNB classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"cleaned_only\"\n",
    "SAMPLING_METHOD = \"undersampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in naive_bayes_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ac26f6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "MultinomialNB classifier       0.5951       âœ… Completed\n",
      "BernoulliNB classifier         0.6050       âœ… Completed\n",
      "ComplementNB classifier        0.5951       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_cleaned_only_undersampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "93e1baba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: MultinomialNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5820\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5803\n",
      "   Micro F1:     0.5820\n",
      "   Weighted F1:  0.5803\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5834  R: 0.5820\n",
      "   Micro    - P: 0.5820  R: 0.5820\n",
      "   Weighted - P: 0.5834  R: 0.5820\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5727     0.6463     0.6073        902\n",
      "   Not Fit              0.5941     0.5177     0.5533        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5834     0.5820     0.5803       1804\n",
      "   weighted avg         0.5834     0.5820     0.5803       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           583      319 \n",
      "   Not Fit       435      467 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'MultinomialNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: BernoulliNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5831\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5827\n",
      "   Micro F1:     0.5831\n",
      "   Weighted F1:  0.5827\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5835  R: 0.5831\n",
      "   Micro    - P: 0.5831  R: 0.5831\n",
      "   Weighted - P: 0.5835  R: 0.5831\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5780     0.6164     0.5966        902\n",
      "   Not Fit              0.5891     0.5499     0.5688        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5835     0.5831     0.5827       1804\n",
      "   weighted avg         0.5835     0.5831     0.5827       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           556      346 \n",
      "   Not Fit       406      496 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'BernoulliNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ComplementNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5820\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5803\n",
      "   Micro F1:     0.5820\n",
      "   Weighted F1:  0.5803\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5834  R: 0.5820\n",
      "   Micro    - P: 0.5820  R: 0.5820\n",
      "   Weighted - P: 0.5834  R: 0.5820\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5727     0.6463     0.6073        902\n",
      "   Not Fit              0.5941     0.5177     0.5533        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5834     0.5820     0.5803       1804\n",
      "   weighted avg         0.5834     0.5820     0.5803       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           583      319 \n",
      "   Not Fit       435      467 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ComplementNB classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PREPROCESSING_TYPE = \"full_process\"\n",
    "SAMPLING_METHOD = \"undersampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in naive_bayes_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "036d4c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "MultinomialNB classifier       0.5820       âœ… Completed\n",
      "BernoulliNB classifier         0.5831       âœ… Completed\n",
      "ComplementNB classifier        0.5820       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_full_process_undersampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "063a2ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: MultinomialNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5754\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5734\n",
      "   Micro F1:     0.5754\n",
      "   Weighted F1:  0.5734\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5768  R: 0.5754\n",
      "   Micro    - P: 0.5754  R: 0.5754\n",
      "   Weighted - P: 0.5768  R: 0.5754\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5664     0.6430     0.6023        902\n",
      "   Not Fit              0.5872     0.5078     0.5446        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5768     0.5754     0.5734       1804\n",
      "   weighted avg         0.5768     0.5754     0.5734       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           580      322 \n",
      "   Not Fit       444      458 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'MultinomialNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: BernoulliNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5859\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5855\n",
      "   Micro F1:     0.5859\n",
      "   Weighted F1:  0.5855\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5863  R: 0.5859\n",
      "   Micro    - P: 0.5859  R: 0.5859\n",
      "   Weighted - P: 0.5863  R: 0.5859\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5808     0.6175     0.5986        902\n",
      "   Not Fit              0.5917     0.5543     0.5724        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5863     0.5859     0.5855       1804\n",
      "   weighted avg         0.5863     0.5859     0.5855       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           557      345 \n",
      "   Not Fit       402      500 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'BernoulliNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ComplementNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5754\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5734\n",
      "   Micro F1:     0.5754\n",
      "   Weighted F1:  0.5734\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5768  R: 0.5754\n",
      "   Micro    - P: 0.5754  R: 0.5754\n",
      "   Weighted - P: 0.5768  R: 0.5754\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5664     0.6430     0.6023        902\n",
      "   Not Fit              0.5872     0.5078     0.5446        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5768     0.5754     0.5734       1804\n",
      "   weighted avg         0.5768     0.5754     0.5734       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           580      322 \n",
      "   Not Fit       444      458 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ComplementNB classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"cleaned_only\"\n",
    "SAMPLING_METHOD = \"oversampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in naive_bayes_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c09a4a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "MultinomialNB classifier       0.5754       âœ… Completed\n",
      "BernoulliNB classifier         0.5859       âœ… Completed\n",
      "ComplementNB classifier        0.5754       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_cleaned_only_oversampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "22c6e094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: MultinomialNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5754\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5734\n",
      "   Micro F1:     0.5754\n",
      "   Weighted F1:  0.5734\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5768  R: 0.5754\n",
      "   Micro    - P: 0.5754  R: 0.5754\n",
      "   Weighted - P: 0.5768  R: 0.5754\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5664     0.6430     0.6023        902\n",
      "   Not Fit              0.5872     0.5078     0.5446        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5768     0.5754     0.5734       1804\n",
      "   weighted avg         0.5768     0.5754     0.5734       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           580      322 \n",
      "   Not Fit       444      458 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'MultinomialNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: BernoulliNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5859\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5855\n",
      "   Micro F1:     0.5859\n",
      "   Weighted F1:  0.5855\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5863  R: 0.5859\n",
      "   Micro    - P: 0.5859  R: 0.5859\n",
      "   Weighted - P: 0.5863  R: 0.5859\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5808     0.6175     0.5986        902\n",
      "   Not Fit              0.5917     0.5543     0.5724        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5863     0.5859     0.5855       1804\n",
      "   weighted avg         0.5863     0.5859     0.5855       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           557      345 \n",
      "   Not Fit       402      500 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'BernoulliNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ComplementNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,804\n",
      "   Classes: 2\n",
      "   Overall Accuracy: 0.5754\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.5734\n",
      "   Micro F1:     0.5754\n",
      "   Weighted F1:  0.5734\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.5768  R: 0.5754\n",
      "   Micro    - P: 0.5754  R: 0.5754\n",
      "   Weighted - P: 0.5768  R: 0.5754\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Fit                  0.5664     0.6430     0.6023        902\n",
      "   Not Fit              0.5872     0.5078     0.5446        902\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.5768     0.5754     0.5734       1804\n",
      "   weighted avg         0.5768     0.5754     0.5734       1804\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“        Fit  Not Fit \n",
      "   Fit           580      322 \n",
      "   Not Fit       444      458 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ComplementNB classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"full_process\"\n",
    "SAMPLING_METHOD = \"oversampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in naive_bayes_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aad31a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "MultinomialNB classifier       0.5754       âœ… Completed\n",
      "BernoulliNB classifier         0.5859       âœ… Completed\n",
      "ComplementNB classifier        0.5754       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_full_process_oversampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a9df8",
   "metadata": {},
   "source": [
    "## Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "87070289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ExperimentManager, Experiment\n",
    "\n",
    "CLASSIFICATION_TYPE = \"multiclass\"\n",
    "manager = ExperimentManager(f\"../runs/{CLASSIFICATION_TYPE}/baselines/\", [\"Good Fit\", \"Potential Fit\", \"Not Fit\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a381215d",
   "metadata": {},
   "source": [
    "### Linear Models\n",
    "\n",
    "RidgeClassifier performs the best. Unclear if stop word removal and lemmatization are beneficial. Undersampling performs the best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eb9a2145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        penalty='l2',\n",
    "        C=1.0,\n",
    "        solver='lbfgs',\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    \"Ridge\": RidgeClassifier(\n",
    "        alpha=1.0, \n",
    "        class_weight='balanced', \n",
    "        random_state=42\n",
    "    ),\n",
    "    \n",
    "    \"LinearSVC\": LinearSVC(\n",
    "        C=1.0,\n",
    "        class_weight='balanced',\n",
    "        dual=False,\n",
    "        random_state=42,\n",
    "        max_iter=2000\n",
    "    )\n",
    "}\n",
    "\n",
    "MODEL_FAMILY = \"linear_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "641e9ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Logistic Regression classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,332\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4324\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4317\n",
      "   Micro F1:     0.4324\n",
      "   Weighted F1:  0.4317\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4328  R: 0.4324\n",
      "   Micro    - P: 0.4324  R: 0.4324\n",
      "   Weighted - P: 0.4328  R: 0.4324\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4559     0.4077     0.4304        444\n",
      "   Not Fit              0.4442     0.4932     0.4674        444\n",
      "   Potential Fit        0.3982     0.3964     0.3973        444\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4328     0.4324     0.4317       1332\n",
      "   weighted avg         0.4328     0.4324     0.4317       1332\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      181      152      111 \n",
      "   Potentia      105      176      163 \n",
      "   Not Fit       111      114      219 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Logistic Regression classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Ridge classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,332\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4369\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4371\n",
      "   Micro F1:     0.4369\n",
      "   Weighted F1:  0.4371\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4373  R: 0.4369\n",
      "   Micro    - P: 0.4369  R: 0.4369\n",
      "   Weighted - P: 0.4373  R: 0.4369\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4460     0.4369     0.4414        444\n",
      "   Not Fit              0.4545     0.4505     0.4525        444\n",
      "   Potential Fit        0.4114     0.4234     0.4173        444\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4373     0.4369     0.4371       1332\n",
      "   weighted avg         0.4373     0.4369     0.4371       1332\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      194      157       93 \n",
      "   Potentia      109      188      147 \n",
      "   Not Fit       132      112      200 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Ridge classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: LinearSVC classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,332\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4317\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4316\n",
      "   Micro F1:     0.4317\n",
      "   Weighted F1:  0.4316\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4328  R: 0.4317\n",
      "   Micro    - P: 0.4317  R: 0.4317\n",
      "   Weighted - P: 0.4328  R: 0.4317\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4475     0.4032     0.4242        444\n",
      "   Not Fit              0.4447     0.4527     0.4487        444\n",
      "   Potential Fit        0.4062     0.4392     0.4221        444\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4328     0.4317     0.4316       1332\n",
      "   weighted avg         0.4328     0.4317     0.4316       1332\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      179      165      100 \n",
      "   Potentia       98      195      151 \n",
      "   Not Fit       123      120      201 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'LinearSVC classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"cleaned_only\"\n",
    "SAMPLING_METHOD = \"undersampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in linear_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c302821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Logistic Regression classifier 0.4324       âœ… Completed\n",
      "Ridge classifier               0.4369       âœ… Completed\n",
      "LinearSVC classifier           0.4317       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_cleaned_only_undersampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b12aad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Logistic Regression classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4539\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4538\n",
      "   Micro F1:     0.4539\n",
      "   Weighted F1:  0.4538\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4550  R: 0.4539\n",
      "   Micro    - P: 0.4539  R: 0.4539\n",
      "   Weighted - P: 0.4550  R: 0.4539\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4903     0.4422     0.4650        857\n",
      "   Not Fit              0.4593     0.5006     0.4791        857\n",
      "   Potential Fit        0.4155     0.4189     0.4172        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4550     0.4539     0.4538       2571\n",
      "   weighted avg         0.4550     0.4539     0.4538       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      379      281      197 \n",
      "   Potentia      190      359      308 \n",
      "   Not Fit       204      224      429 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Logistic Regression classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Ridge classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4547\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4559\n",
      "   Micro F1:     0.4547\n",
      "   Weighted F1:  0.4559\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4583  R: 0.4547\n",
      "   Micro    - P: 0.4547  R: 0.4547\n",
      "   Weighted - P: 0.4583  R: 0.4547\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.5315     0.4819     0.5055        857\n",
      "   Not Fit              0.4446     0.4586     0.4515        857\n",
      "   Potential Fit        0.3989     0.4236     0.4109        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4583     0.4547     0.4559       2571\n",
      "   weighted avg         0.4583     0.4547     0.4559       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      413      277      167 \n",
      "   Potentia      170      363      324 \n",
      "   Not Fit       194      270      393 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Ridge classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: LinearSVC classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4411\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4422\n",
      "   Micro F1:     0.4411\n",
      "   Weighted F1:  0.4422\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4475  R: 0.4411\n",
      "   Micro    - P: 0.4411  R: 0.4411\n",
      "   Weighted - P: 0.4475  R: 0.4411\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.5220     0.4282     0.4705        857\n",
      "   Not Fit              0.4304     0.4761     0.4521        857\n",
      "   Potential Fit        0.3902     0.4189     0.4041        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4475     0.4411     0.4422       2571\n",
      "   weighted avg         0.4475     0.4411     0.4422       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      367      288      202 \n",
      "   Potentia      160      359      338 \n",
      "   Not Fit       176      273      408 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'LinearSVC classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PREPROCESSING_TYPE = \"full_process\"\n",
    "SAMPLING_METHOD = \"undersampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in linear_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ac4f1fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Logistic Regression classifier 0.4539       âœ… Completed\n",
      "Ridge classifier               0.4547       âœ… Completed\n",
      "LinearSVC classifier           0.4411       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_full_process_undersampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cccb2751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Logistic Regression classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4508\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4502\n",
      "   Micro F1:     0.4508\n",
      "   Weighted F1:  0.4502\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4513  R: 0.4508\n",
      "   Micro    - P: 0.4508  R: 0.4508\n",
      "   Weighted - P: 0.4513  R: 0.4508\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4690     0.4142     0.4399        857\n",
      "   Not Fit              0.4663     0.5088     0.4866        857\n",
      "   Potential Fit        0.4187     0.4294     0.4240        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4513     0.4508     0.4502       2571\n",
      "   weighted avg         0.4513     0.4508     0.4502       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      355      299      203 \n",
      "   Potentia      193      368      296 \n",
      "   Not Fit       209      212      436 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Logistic Regression classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Ridge classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4422\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4428\n",
      "   Micro F1:     0.4422\n",
      "   Weighted F1:  0.4428\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4441  R: 0.4422\n",
      "   Micro    - P: 0.4422  R: 0.4422\n",
      "   Weighted - P: 0.4441  R: 0.4422\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4873     0.4492     0.4675        857\n",
      "   Not Fit              0.4554     0.4702     0.4627        857\n",
      "   Potential Fit        0.3895     0.4072     0.3982        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4441     0.4422     0.4428       2571\n",
      "   weighted avg         0.4441     0.4422     0.4428       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      385      306      166 \n",
      "   Potentia      192      349      316 \n",
      "   Not Fit       213      241      403 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Ridge classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: LinearSVC classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4356\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4355\n",
      "   Micro F1:     0.4356\n",
      "   Weighted F1:  0.4355\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4387  R: 0.4356\n",
      "   Micro    - P: 0.4356  R: 0.4356\n",
      "   Weighted - P: 0.4387  R: 0.4356\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4931     0.4154     0.4509        857\n",
      "   Not Fit              0.4443     0.5029     0.4718        857\n",
      "   Potential Fit        0.3788     0.3886     0.3836        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4387     0.4356     0.4355       2571\n",
      "   weighted avg         0.4387     0.4356     0.4355       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      356      308      193 \n",
      "   Potentia      178      333      346 \n",
      "   Not Fit       188      238      431 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'LinearSVC classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"cleaned_only\"\n",
    "SAMPLING_METHOD = \"oversampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in linear_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3775cc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Logistic Regression classifier 0.4508       âœ… Completed\n",
      "Ridge classifier               0.4422       âœ… Completed\n",
      "LinearSVC classifier           0.4356       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_cleaned_only_oversampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b0fa0395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Logistic Regression classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4508\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4502\n",
      "   Micro F1:     0.4508\n",
      "   Weighted F1:  0.4502\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4513  R: 0.4508\n",
      "   Micro    - P: 0.4508  R: 0.4508\n",
      "   Weighted - P: 0.4513  R: 0.4508\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4690     0.4142     0.4399        857\n",
      "   Not Fit              0.4663     0.5088     0.4866        857\n",
      "   Potential Fit        0.4187     0.4294     0.4240        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4513     0.4508     0.4502       2571\n",
      "   weighted avg         0.4513     0.4508     0.4502       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      355      299      203 \n",
      "   Potentia      193      368      296 \n",
      "   Not Fit       209      212      436 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Logistic Regression classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Ridge classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4422\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4428\n",
      "   Micro F1:     0.4422\n",
      "   Weighted F1:  0.4428\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4441  R: 0.4422\n",
      "   Micro    - P: 0.4422  R: 0.4422\n",
      "   Weighted - P: 0.4441  R: 0.4422\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4873     0.4492     0.4675        857\n",
      "   Not Fit              0.4554     0.4702     0.4627        857\n",
      "   Potential Fit        0.3895     0.4072     0.3982        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4441     0.4422     0.4428       2571\n",
      "   weighted avg         0.4441     0.4422     0.4428       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      385      306      166 \n",
      "   Potentia      192      349      316 \n",
      "   Not Fit       213      241      403 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Ridge classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: LinearSVC classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4356\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4355\n",
      "   Micro F1:     0.4356\n",
      "   Weighted F1:  0.4355\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4387  R: 0.4356\n",
      "   Micro    - P: 0.4356  R: 0.4356\n",
      "   Weighted - P: 0.4387  R: 0.4356\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4931     0.4154     0.4509        857\n",
      "   Not Fit              0.4443     0.5029     0.4718        857\n",
      "   Potential Fit        0.3788     0.3886     0.3836        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4387     0.4356     0.4355       2571\n",
      "   weighted avg         0.4387     0.4356     0.4355       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      356      308      193 \n",
      "   Potentia      178      333      346 \n",
      "   Not Fit       188      238      431 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'LinearSVC classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"full_process\"\n",
    "SAMPLING_METHOD = \"oversampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in linear_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b98eb492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Logistic Regression classifier 0.4508       âœ… Completed\n",
      "Ridge classifier               0.4422       âœ… Completed\n",
      "LinearSVC classifier           0.4356       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_full_process_oversampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5df2c7",
   "metadata": {},
   "source": [
    "### Tree Models\n",
    "\n",
    "RidgeClassifier performs the best. Unclear if stop word removal and lemmatization are beneficial. Undersampling performs the best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b0684e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "tree_models = {\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    \"ExtraTrees\": ExtraTreesClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        max_depth=None,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2\n",
    "    )\n",
    "}\n",
    "\n",
    "MODEL_FAMILY = \"tree_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "522b9e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Random Forest classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,332\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4459\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4453\n",
      "   Micro F1:     0.4459\n",
      "   Weighted F1:  0.4453\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4511  R: 0.4459\n",
      "   Micro    - P: 0.4459  R: 0.4459\n",
      "   Weighted - P: 0.4511  R: 0.4459\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.5029     0.3919     0.4405        444\n",
      "   Not Fit              0.4497     0.5135     0.4795        444\n",
      "   Potential Fit        0.4008     0.4324     0.4160        444\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4511     0.4459     0.4453       1332\n",
      "   weighted avg         0.4511     0.4459     0.4453       1332\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      174      163      107 \n",
      "   Potentia       80      192      172 \n",
      "   Not Fit        92      124      228 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Random Forest classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ExtraTrees classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,332\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4467\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4446\n",
      "   Micro F1:     0.4467\n",
      "   Weighted F1:  0.4446\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4559  R: 0.4467\n",
      "   Micro    - P: 0.4467  R: 0.4467\n",
      "   Weighted - P: 0.4559  R: 0.4467\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.5180     0.3559     0.4219        444\n",
      "   Not Fit              0.4480     0.5338     0.4872        444\n",
      "   Potential Fit        0.4016     0.4505     0.4246        444\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4559     0.4467     0.4446       1332\n",
      "   weighted avg         0.4559     0.4467     0.4446       1332\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      158      175      111 \n",
      "   Potentia       63      200      181 \n",
      "   Not Fit        84      123      237 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ExtraTrees classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"cleaned_only\"\n",
    "SAMPLING_METHOD = \"undersampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in tree_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f102d88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Random Forest classifier       0.4459       âœ… Completed\n",
      "ExtraTrees classifier          0.4467       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_cleaned_only_undersampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6cde8936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Random Forest classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4391\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4260\n",
      "   Micro F1:     0.4391\n",
      "   Weighted F1:  0.4260\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4487  R: 0.4391\n",
      "   Micro    - P: 0.4391  R: 0.4391\n",
      "   Weighted - P: 0.4487  R: 0.4391\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4971     0.2964     0.3713        857\n",
      "   Not Fit              0.4254     0.6616     0.5178        857\n",
      "   Potential Fit        0.4237     0.3594     0.3889        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4487     0.4391     0.4260       2571\n",
      "   weighted avg         0.4487     0.4391     0.4260       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      254      251      352 \n",
      "   Potentia      135      308      414 \n",
      "   Not Fit       122      168      567 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Random Forest classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ExtraTrees classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4516\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4316\n",
      "   Micro F1:     0.4516\n",
      "   Weighted F1:  0.4316\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4924  R: 0.4516\n",
      "   Micro    - P: 0.4516  R: 0.4516\n",
      "   Weighted - P: 0.4924  R: 0.4516\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.5884     0.2719     0.3719        857\n",
      "   Not Fit              0.4048     0.7445     0.5245        857\n",
      "   Potential Fit        0.4841     0.3384     0.3984        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4924     0.4516     0.4316       2571\n",
      "   weighted avg         0.4924     0.4516     0.4316       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      233      176      448 \n",
      "   Potentia       77      290      490 \n",
      "   Not Fit        86      133      638 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ExtraTrees classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PREPROCESSING_TYPE = \"full_process\"\n",
    "SAMPLING_METHOD = \"undersampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in tree_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "24bd87ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Random Forest classifier       0.4391       âœ… Completed\n",
      "ExtraTrees classifier          0.4516       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_full_process_undersampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4c2e93e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Random Forest classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4539\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4455\n",
      "   Micro F1:     0.4539\n",
      "   Weighted F1:  0.4455\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4729  R: 0.4539\n",
      "   Micro    - P: 0.4539  R: 0.4539\n",
      "   Weighted - P: 0.4729  R: 0.4539\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.5614     0.3256     0.4121        857\n",
      "   Not Fit              0.4267     0.6418     0.5126        857\n",
      "   Potential Fit        0.4306     0.3944     0.4117        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4729     0.4539     0.4455       2571\n",
      "   weighted avg         0.4729     0.4539     0.4455       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      279      251      327 \n",
      "   Potentia      107      338      412 \n",
      "   Not Fit       111      196      550 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Random Forest classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ExtraTrees classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4255\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4022\n",
      "   Micro F1:     0.4255\n",
      "   Weighted F1:  0.4022\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4490  R: 0.4255\n",
      "   Micro    - P: 0.4255  R: 0.4255\n",
      "   Weighted - P: 0.4490  R: 0.4255\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.5216     0.2392     0.3280        857\n",
      "   Not Fit              0.4017     0.7200     0.5157        857\n",
      "   Potential Fit        0.4237     0.3174     0.3629        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4490     0.4255     0.4022       2571\n",
      "   weighted avg         0.4490     0.4255     0.4022       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      205      221      431 \n",
      "   Potentia       97      272      488 \n",
      "   Not Fit        91      149      617 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ExtraTrees classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"cleaned_only\"\n",
    "SAMPLING_METHOD = \"oversampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in tree_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "94e4c87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Random Forest classifier       0.4539       âœ… Completed\n",
      "ExtraTrees classifier          0.4255       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_cleaned_only_oversampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ea34a034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: Random Forest classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4539\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4455\n",
      "   Micro F1:     0.4539\n",
      "   Weighted F1:  0.4455\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4729  R: 0.4539\n",
      "   Micro    - P: 0.4539  R: 0.4539\n",
      "   Weighted - P: 0.4729  R: 0.4539\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.5614     0.3256     0.4121        857\n",
      "   Not Fit              0.4267     0.6418     0.5126        857\n",
      "   Potential Fit        0.4306     0.3944     0.4117        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4729     0.4539     0.4455       2571\n",
      "   weighted avg         0.4729     0.4539     0.4455       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      279      251      327 \n",
      "   Potentia      107      338      412 \n",
      "   Not Fit       111      196      550 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'Random Forest classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ExtraTrees classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4255\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4022\n",
      "   Micro F1:     0.4255\n",
      "   Weighted F1:  0.4022\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4490  R: 0.4255\n",
      "   Micro    - P: 0.4255  R: 0.4255\n",
      "   Weighted - P: 0.4490  R: 0.4255\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.5216     0.2392     0.3280        857\n",
      "   Not Fit              0.4017     0.7200     0.5157        857\n",
      "   Potential Fit        0.4237     0.3174     0.3629        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4490     0.4255     0.4022       2571\n",
      "   weighted avg         0.4490     0.4255     0.4022       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      205      221      431 \n",
      "   Potentia       97      272      488 \n",
      "   Not Fit        91      149      617 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ExtraTrees classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"full_process\"\n",
    "SAMPLING_METHOD = \"oversampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in tree_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "48445204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "Random Forest classifier       0.4539       âœ… Completed\n",
      "ExtraTrees classifier          0.4255       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_full_process_oversampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bed6bf",
   "metadata": {},
   "source": [
    "### Naive Bayes Models\n",
    "\n",
    "RidgeClassifier performs the best. Unclear if stop word removal and lemmatization are beneficial. Undersampling performs the best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9eb0042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, ComplementNB\n",
    "\n",
    "naive_bayes_models = {\n",
    "    \"MultinomialNB\": MultinomialNB(\n",
    "        alpha=1.0,\n",
    "        fit_prior=True\n",
    "    ),\n",
    "    \n",
    "    \"BernoulliNB\": BernoulliNB(\n",
    "        alpha=1.0,\n",
    "        binarize=0.0,\n",
    "        fit_prior=True\n",
    "    ),\n",
    "    \n",
    "    \"ComplementNB\": ComplementNB(\n",
    "        alpha=1.0,\n",
    "        fit_prior=True,\n",
    "        norm=False\n",
    "    )\n",
    "}\n",
    "\n",
    "MODEL_FAMILY = \"naive_bayes_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "628b1bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: MultinomialNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,332\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4287\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4248\n",
      "   Micro F1:     0.4287\n",
      "   Weighted F1:  0.4248\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4283  R: 0.4287\n",
      "   Micro    - P: 0.4287  R: 0.4287\n",
      "   Weighted - P: 0.4283  R: 0.4287\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4291     0.5450     0.4802        444\n",
      "   Not Fit              0.4665     0.4077     0.4351        444\n",
      "   Potential Fit        0.3895     0.3333     0.3592        444\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4283     0.4287     0.4248       1332\n",
      "   weighted avg         0.4283     0.4287     0.4248       1332\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      242      124       78 \n",
      "   Potentia      167      148      129 \n",
      "   Not Fit       155      108      181 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'MultinomialNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: BernoulliNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,332\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4497\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4497\n",
      "   Micro F1:     0.4497\n",
      "   Weighted F1:  0.4497\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4502  R: 0.4497\n",
      "   Micro    - P: 0.4497  R: 0.4497\n",
      "   Weighted - P: 0.4502  R: 0.4497\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4355     0.4640     0.4493        444\n",
      "   Not Fit              0.4791     0.4640     0.4714        444\n",
      "   Potential Fit        0.4359     0.4212     0.4284        444\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4502     0.4497     0.4497       1332\n",
      "   weighted avg         0.4502     0.4497     0.4497       1332\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      206      138      100 \n",
      "   Potentia      133      187      124 \n",
      "   Not Fit       134      104      206 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'BernoulliNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ComplementNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 1,332\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4384\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4329\n",
      "   Micro F1:     0.4384\n",
      "   Weighted F1:  0.4329\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4389  R: 0.4384\n",
      "   Micro    - P: 0.4384  R: 0.4384\n",
      "   Weighted - P: 0.4389  R: 0.4384\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4368     0.5833     0.4995        444\n",
      "   Not Fit              0.4810     0.3986     0.4360        444\n",
      "   Potential Fit        0.3989     0.3333     0.3632        444\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4389     0.4384     0.4329       1332\n",
      "   weighted avg         0.4389     0.4384     0.4329       1332\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      259      116       69 \n",
      "   Potentia      174      148      122 \n",
      "   Not Fit       160      107      177 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ComplementNB classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"cleaned_only\"\n",
    "SAMPLING_METHOD = \"undersampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in naive_bayes_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "715cf645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "MultinomialNB classifier       0.4287       âœ… Completed\n",
      "BernoulliNB classifier         0.4497       âœ… Completed\n",
      "ComplementNB classifier        0.4384       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_cleaned_only_undersampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7fb676ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: MultinomialNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4465\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4459\n",
      "   Micro F1:     0.4465\n",
      "   Weighted F1:  0.4459\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4498  R: 0.4465\n",
      "   Micro    - P: 0.4465  R: 0.4465\n",
      "   Weighted - P: 0.4498  R: 0.4465\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4613     0.4936     0.4769        857\n",
      "   Not Fit              0.4791     0.3874     0.4284        857\n",
      "   Potential Fit        0.4089     0.4586     0.4323        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4498     0.4465     0.4459       2571\n",
      "   weighted avg         0.4498     0.4465     0.4459       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      423      293      141 \n",
      "   Potentia      244      393      220 \n",
      "   Not Fit       250      275      332 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'MultinomialNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: BernoulliNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4364\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4360\n",
      "   Micro F1:     0.4364\n",
      "   Weighted F1:  0.4360\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4377  R: 0.4364\n",
      "   Micro    - P: 0.4364  R: 0.4364\n",
      "   Weighted - P: 0.4377  R: 0.4364\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4543     0.3944     0.4222        857\n",
      "   Not Fit              0.4482     0.4691     0.4584        857\n",
      "   Potential Fit        0.4108     0.4457     0.4275        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4377     0.4364     0.4360       2571\n",
      "   weighted avg         0.4377     0.4364     0.4360       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      338      307      212 \n",
      "   Potentia      192      382      283 \n",
      "   Not Fit       214      241      402 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'BernoulliNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ComplementNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4489\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4481\n",
      "   Micro F1:     0.4489\n",
      "   Weighted F1:  0.4481\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4527  R: 0.4489\n",
      "   Micro    - P: 0.4489  R: 0.4489\n",
      "   Weighted - P: 0.4527  R: 0.4489\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4615     0.5169     0.4876        857\n",
      "   Not Fit              0.4934     0.3921     0.4369        857\n",
      "   Potential Fit        0.4032     0.4376     0.4197        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4527     0.4489     0.4481       2571\n",
      "   weighted avg         0.4527     0.4489     0.4481       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      443      286      128 \n",
      "   Potentia      265      375      217 \n",
      "   Not Fit       252      269      336 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ComplementNB classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PREPROCESSING_TYPE = \"full_process\"\n",
    "SAMPLING_METHOD = \"undersampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in naive_bayes_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5924bda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "MultinomialNB classifier       0.4465       âœ… Completed\n",
      "BernoulliNB classifier         0.4364       âœ… Completed\n",
      "ComplementNB classifier        0.4489       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_full_process_undersampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "53697964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: MultinomialNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4411\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4401\n",
      "   Micro F1:     0.4411\n",
      "   Weighted F1:  0.4401\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4439  R: 0.4411\n",
      "   Micro    - P: 0.4411  R: 0.4411\n",
      "   Weighted - P: 0.4439  R: 0.4411\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4613     0.4936     0.4769        857\n",
      "   Not Fit              0.4666     0.3746     0.4155        857\n",
      "   Potential Fit        0.4037     0.4551     0.4279        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4439     0.4411     0.4401       2571\n",
      "   weighted avg         0.4439     0.4411     0.4401       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      423      297      137 \n",
      "   Potentia      237      390      230 \n",
      "   Not Fit       257      279      321 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'MultinomialNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: BernoulliNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4321\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4321\n",
      "   Micro F1:     0.4321\n",
      "   Weighted F1:  0.4321\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4333  R: 0.4321\n",
      "   Micro    - P: 0.4321  R: 0.4321\n",
      "   Weighted - P: 0.4333  R: 0.4321\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4414     0.3956     0.4172        857\n",
      "   Not Fit              0.4627     0.4702     0.4664        857\n",
      "   Potential Fit        0.3959     0.4306     0.4125        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4333     0.4321     0.4321       2571\n",
      "   weighted avg         0.4333     0.4321     0.4321       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      339      335      183 \n",
      "   Potentia      203      369      285 \n",
      "   Not Fit       226      228      403 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'BernoulliNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ComplementNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4430\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4420\n",
      "   Micro F1:     0.4430\n",
      "   Weighted F1:  0.4420\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4456  R: 0.4430\n",
      "   Micro    - P: 0.4430  R: 0.4430\n",
      "   Weighted - P: 0.4456  R: 0.4430\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4618     0.5146     0.4868        857\n",
      "   Not Fit              0.4761     0.3839     0.4251        857\n",
      "   Potential Fit        0.3989     0.4306     0.4141        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4456     0.4430     0.4420       2571\n",
      "   weighted avg         0.4456     0.4430     0.4420       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      441      288      128 \n",
      "   Potentia      254      369      234 \n",
      "   Not Fit       260      268      329 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ComplementNB classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"cleaned_only\"\n",
    "SAMPLING_METHOD = \"oversampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in naive_bayes_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3c28c7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "MultinomialNB classifier       0.4411       âœ… Completed\n",
      "BernoulliNB classifier         0.4321       âœ… Completed\n",
      "ComplementNB classifier        0.4430       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_cleaned_only_oversampled.csv\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "991c4092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: MultinomialNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4411\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4401\n",
      "   Micro F1:     0.4411\n",
      "   Weighted F1:  0.4401\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4439  R: 0.4411\n",
      "   Micro    - P: 0.4411  R: 0.4411\n",
      "   Weighted - P: 0.4439  R: 0.4411\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4613     0.4936     0.4769        857\n",
      "   Not Fit              0.4666     0.3746     0.4155        857\n",
      "   Potential Fit        0.4037     0.4551     0.4279        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4439     0.4411     0.4401       2571\n",
      "   weighted avg         0.4439     0.4411     0.4401       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      423      297      137 \n",
      "   Potentia      237      390      230 \n",
      "   Not Fit       257      279      321 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'MultinomialNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: BernoulliNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4321\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4321\n",
      "   Micro F1:     0.4321\n",
      "   Weighted F1:  0.4321\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4333  R: 0.4321\n",
      "   Micro    - P: 0.4321  R: 0.4321\n",
      "   Weighted - P: 0.4333  R: 0.4321\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4414     0.3956     0.4172        857\n",
      "   Not Fit              0.4627     0.4702     0.4664        857\n",
      "   Potential Fit        0.3959     0.4306     0.4125        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4333     0.4321     0.4321       2571\n",
      "   weighted avg         0.4333     0.4321     0.4321       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      339      335      183 \n",
      "   Potentia      203      369      285 \n",
      "   Not Fit       226      228      403 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'BernoulliNB classifier' completed and logged.\n",
      "\n",
      "========= Training Baseline Models =========\n",
      "\n",
      "=== Running Experiment: ComplementNB classifier ===\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ TEST SET EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š OVERVIEW\n",
      "   Test Samples: 2,571\n",
      "   Classes: 3\n",
      "   Overall Accuracy: 0.4430\n",
      "\n",
      "ðŸŽ¯ MAIN PERFORMANCE METRICS\n",
      "   Macro F1:     0.4420\n",
      "   Micro F1:     0.4430\n",
      "   Weighted F1:  0.4420\n",
      "\n",
      "ðŸ“ˆ PRECISION/RECALL SUMMARY\n",
      "   Macro    - P: 0.4456  R: 0.4430\n",
      "   Micro    - P: 0.4430  R: 0.4430\n",
      "   Weighted - P: 0.4456  R: 0.4430\n",
      "\n",
      "ðŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "   Class             Precision     Recall   F1-Score    Support\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   Good Fit             0.4618     0.5146     0.4868        857\n",
      "   Not Fit              0.4761     0.3839     0.4251        857\n",
      "   Potential Fit        0.3989     0.4306     0.4141        857\n",
      "   ---------------- ---------- ---------- ---------- ----------\n",
      "   macro avg            0.4456     0.4430     0.4420       2571\n",
      "   weighted avg         0.4456     0.4430     0.4420       2571\n",
      "\n",
      "ðŸ”¢ CONFUSION MATRIX\n",
      "   Rows: True Labels, Columns: Predicted Labels\n",
      "   Predicted â†’\n",
      "   True â†“   Good Fit Potentia  Not Fit \n",
      "   Good Fit      441      288      128 \n",
      "   Potentia      254      369      234 \n",
      "   Not Fit       260      268      329 \n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Finalizing experiment...\n",
      "\n",
      "âœ… Experiment 'ComplementNB classifier' completed and logged.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREPROCESSING_TYPE = \"full_process\"\n",
    "SAMPLING_METHOD = \"oversampled\"\n",
    "\n",
    "splits = load_split(\n",
    "    preprocessing_type=PREPROCESSING_TYPE,\n",
    "    sampling_method=SAMPLING_METHOD,\n",
    "    classification_type=CLASSIFICATION_TYPE\n",
    "    )\n",
    "\n",
    "for name, model in naive_bayes_models.items():\n",
    "\n",
    "    # Pipeline\n",
    "    def pipeline_factory(params):\n",
    "        # Since weâ€™re not using params here, we just return the static pipeline\n",
    "        return Pipeline([\n",
    "        (\"join\", FunctionTransformer(combine_text, validate=False)),\n",
    "        ('tfidf', TfidfVectorizer()),  # Convert text to numeric\n",
    "        ('clf', model)  \n",
    "    ])\n",
    "\n",
    "    experiment = Experiment(\n",
    "        name=f\"{name} classifier\",\n",
    "        description=f\"\"\"\n",
    "{CLASSIFICATION_TYPE} {name} with TF-IDF and no hyperparameter tuning. \n",
    "Dataset has {PREPROCESSING_TYPE} preprocessing and is {SAMPLING_METHOD}\n",
    "\"\"\",\n",
    "        pipeline_factory=pipeline_factory\n",
    "    )\n",
    "\n",
    "    print(\"========= Training Baseline Models =========\")\n",
    "    manager.run_experiment(experiment, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e44bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Experiment Comparison (accuracy) ===\n",
      "Experiment                     Test Score   Status    \n",
      "-------------------------------------------------------\n",
      "MultinomialNB classifier       0.4411       âœ… Completed\n",
      "BernoulliNB classifier         0.4321       âœ… Completed\n",
      "ComplementNB classifier        0.4430       âœ… Completed\n",
      "ðŸ“Š Experiment summary exported to: summary_full_process_oversampled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7fa68eba8540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7fbbf54ac540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7fad45394540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7f23dc49c540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7f02933a0540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7fe2a2f90540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7fda53498540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7f8a8e2ac540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7f1d0ceac540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7f22b1aa4540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7f3a0eeac540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7facab0ac540>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/home/maveron/.conda/envs/304/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "dir = f\"../experiment_summaries/{MODEL_FAMILY}/{CLASSIFICATION_TYPE}\"\n",
    "file = f\"summary_{PREPROCESSING_TYPE}_{SAMPLING_METHOD}.csv\"\n",
    "\n",
    "manager.compare_experiments()\n",
    "manager.export_experiment_summary(dir = dir, filename = file)\n",
    "manager.experiments = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "304",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
