{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f9e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2297523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading train/val data...\n",
      "✅ Data loaded:\n",
      "   X_train: (2100, 5000)\n",
      "   X_val: (600, 5000)\n",
      "   y_train: 2100 samples\n",
      "   y_val: 600 samples\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "from utils import load_train_val_data\n",
    "\n",
    "X_train, X_val, y_train, y_val = load_train_val_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9045d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_pipeline import ModelTrainer\n",
    "\n",
    "# Create trainer (same config as RF)\n",
    "trainer = ModelTrainer(\n",
    "    cv_folds=8,\n",
    "    scoring='f1_weighted', \n",
    "    n_trials=20,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e8a3001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ SCALING IMPACT TEST\n",
      "==============================\n",
      "\n",
      "🧪 Testing WITHOUT scaling...\n",
      "🚀 Training LR_Unscaled...\n",
      "🔧 Fitting LR_Unscaled...\n",
      "✅ LR_Unscaled fitted in 1.47 seconds\n",
      "🔄 Running 8-fold cross-validation...\n",
      "✅ LR_Unscaled completed in 2.7s\n",
      "   CV: 0.5071 ± 0.0288\n",
      "   Train: 0.6424\n",
      "   Val: 0.5250 (gap: 0.1174)\n",
      "Data type: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Is sparse: True\n",
      "Converting sparse matrix to dense...\n",
      "📏 Scaler fitted on (2100, 5000) training data\n",
      "✅ Scaling completed:\n",
      "   Train: (2100, 5000) (mean: 0.000, std: 1.000)\n",
      "   Val: (600, 5000) (mean: -0.002, std: 1.001)\n",
      "🚀 Training LR_Scaled...\n",
      "🔧 Fitting LR_Scaled...\n",
      "✅ LR_Scaled fitted in 17.62 seconds\n",
      "🔄 Running 8-fold cross-validation...\n",
      "✅ LR_Scaled completed in 26.5s\n",
      "   CV: 0.6320 ± 0.0397\n",
      "   Train: 0.9686\n",
      "   Val: 0.6417 (gap: 0.3269)\n",
      "\n",
      "📊 SCALING COMPARISON:\n",
      "   Unscaled: 0.5250\n",
      "   Scaled:   0.6417\n",
      "   Improvement: +0.1167\n"
     ]
    }
   ],
   "source": [
    "from utils.SimpleScaler import SimpleScaler\n",
    "from models.LogisticRegressionModel import LogisticRegressionModel\n",
    "\n",
    "# QUICK SCALING COMPARISON\n",
    "print(\"⚡ SCALING IMPACT TEST\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Test 1: No scaling\n",
    "print(\"\\n🧪 Testing WITHOUT scaling...\")\n",
    "lr_unscaled = LogisticRegressionModel(\n",
    "    solver='lbfgs',  # Changed from liblinear to avoid warnings\n",
    "    max_iter=3000    # Increased iterations\n",
    ")\n",
    "lr_unscaled.name = \"LR_Unscaled\"\n",
    "\n",
    "unscaled_results = trainer.train_model(\n",
    "    model=lr_unscaled,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    optimize=False\n",
    ")\n",
    "\n",
    "# Test 2: With scaling\n",
    "\n",
    "print(f\"Data type: {type(X_train)}\")\n",
    "print(f\"Is sparse: {hasattr(X_train, 'sparse') or 'sparse' in str(type(X_train)).lower()}\")\n",
    "\n",
    "# Convert to dense if sparse (this fixes the StandardScaler issue)\n",
    "if hasattr(X_train, 'toarray'):\n",
    "    print(\"Converting sparse matrix to dense...\")\n",
    "    X_train_dense = X_train.toarray()\n",
    "    X_val_dense = X_val.toarray()\n",
    "else:\n",
    "    X_train_dense = X_train\n",
    "    X_val_dense = X_val\n",
    "\n",
    "# Now scale the dense data\n",
    "scaler = SimpleScaler()\n",
    "X_train_scaled, X_val_scaled = scaler.fit_transform_split(X_train_dense, X_val_dense)\n",
    "\n",
    "lr_scaled = LogisticRegressionModel(\n",
    "    solver='lbfgs',  # Using lbfgs instead of liblinear\n",
    "    max_iter=3000\n",
    ")\n",
    "lr_scaled.name = \"LR_Scaled\"\n",
    "\n",
    "scaled_results = trainer.train_model(\n",
    "    model=lr_scaled,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val_scaled,\n",
    "    y_val=y_val,\n",
    "    optimize=False\n",
    ")\n",
    "\n",
    "# Compare\n",
    "print(f\"\\n📊 SCALING COMPARISON:\")\n",
    "print(f\"   Unscaled: {unscaled_results['val_accuracy']:.4f}\")\n",
    "print(f\"   Scaled:   {scaled_results['val_accuracy']:.4f}\")\n",
    "print(f\"   Improvement: {scaled_results['val_accuracy'] - unscaled_results['val_accuracy']:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa5cf8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 09:05:41,987] A new study created in memory with name: no-name-f5f78ae9-9fb5-4564-b373-dba1b2f167b4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 FINAL OPTIMIZATION - Best Feature Selection\n",
      "==================================================\n",
      "\n",
      "🧪 Testing anti_overfitting strategy...\n",
      "🚀 Training LR_anti_overfitting...\n",
      "🔍 Optimizing LR_anti_overfitting hyperparameters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99f61176813431caf5f394f6cae6d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 09:13:01,436] Trial 0 finished with value: 0.6374009724105645 and parameters: {'C': 0.37516557872851514, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 3796}. Best is trial 0 with value: 0.6374009724105645.\n",
      "[I 2025-06-19 09:16:49,688] Trial 1 finished with value: 0.6232093489795265 and parameters: {'C': 0.1568626218019941, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 4599}. Best is trial 0 with value: 0.6374009724105645.\n",
      "[I 2025-06-19 09:26:11,027] Trial 2 finished with value: 0.6326313964556711 and parameters: {'C': 0.6015138967314656, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 4910}. Best is trial 0 with value: 0.6374009724105645.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 09:32:18,364] Trial 3 finished with value: 0.6327922335626527 and parameters: {'C': 0.8326101981596213, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 2550}. Best is trial 0 with value: 0.6374009724105645.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 09:38:36,123] Trial 4 finished with value: 0.6318425666853835 and parameters: {'C': 0.3049380007165782, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 2873}. Best is trial 0 with value: 0.6374009724105645.\n",
      "[I 2025-06-19 09:41:36,093] Trial 5 finished with value: 0.6217102531335204 and parameters: {'C': 0.612241041827657, 'penalty': 'l2', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 3099}. Best is trial 0 with value: 0.6374009724105645.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 09:49:27,069] Trial 6 finished with value: 0.6372767794514551 and parameters: {'C': 0.4566139142328189, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 3543}. Best is trial 0 with value: 0.6374009724105645.\n",
      "[I 2025-06-19 09:52:22,814] Trial 7 finished with value: 0.6221968166585807 and parameters: {'C': 0.5928221542931804, 'penalty': 'l2', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 2511}. Best is trial 0 with value: 0.6374009724105645.\n",
      "[I 2025-06-19 09:53:29,061] Trial 8 finished with value: 0.6283087924755314 and parameters: {'C': 0.06598654139229423, 'penalty': 'l2', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 4426}. Best is trial 0 with value: 0.6374009724105645.\n",
      "[I 2025-06-19 09:55:45,609] Trial 9 finished with value: 0.6235172864292968 and parameters: {'C': 0.30530915540419734, 'penalty': 'l2', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 3320}. Best is trial 0 with value: 0.6374009724105645.\n",
      "[I 2025-06-19 10:04:51,937] Trial 10 finished with value: 0.6293282065655563 and parameters: {'C': 0.9451914076861564, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 4089}. Best is trial 0 with value: 0.6374009724105645.\n",
      "[I 2025-06-19 10:12:02,950] Trial 11 finished with value: 0.6369197935587841 and parameters: {'C': 0.3945685592735172, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 3773}. Best is trial 0 with value: 0.6374009724105645.\n",
      "[I 2025-06-19 10:19:49,541] Trial 12 finished with value: 0.6382436075429607 and parameters: {'C': 0.42332857369445503, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 3712}. Best is trial 12 with value: 0.6382436075429607.\n",
      "[I 2025-06-19 10:25:01,510] Trial 13 finished with value: 0.6302995356459606 and parameters: {'C': 0.23227037028119973, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 3852}. Best is trial 12 with value: 0.6382436075429607.\n",
      "[I 2025-06-19 10:34:15,774] Trial 14 finished with value: 0.6297673893790006 and parameters: {'C': 0.7657524393955844, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 4172}. Best is trial 12 with value: 0.6382436075429607.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 10:42:05,789] Trial 15 finished with value: 0.6373236290336303 and parameters: {'C': 0.4541219326285934, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 3576}. Best is trial 12 with value: 0.6382436075429607.\n",
      "[I 2025-06-19 10:42:43,092] Trial 16 finished with value: 0.5703279547545035 and parameters: {'C': 0.022723184128547236, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 3043}. Best is trial 12 with value: 0.6382436075429607.\n",
      "[I 2025-06-19 10:49:36,686] Trial 17 finished with value: 0.6360174133211094 and parameters: {'C': 0.3463480515030184, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 4073}. Best is trial 12 with value: 0.6382436075429607.\n",
      "[I 2025-06-19 10:52:26,856] Trial 18 finished with value: 0.6212306053812144 and parameters: {'C': 0.540080486695995, 'penalty': 'l2', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 2178}. Best is trial 12 with value: 0.6382436075429607.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-19 11:00:18,617] Trial 19 finished with value: 0.6311727877658437 and parameters: {'C': 0.7122658244111982, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 3341}. Best is trial 12 with value: 0.6382436075429607.\n",
      "✅ Optimization completed in 6876.6s\n",
      "   Best score: 0.6382\n",
      "   Best params: {'C': 0.42332857369445503, 'penalty': 'l1', 'solver': 'saga', 'class_weight': 'balanced', 'max_iter': 3712}\n",
      "🔧 Fitting LR_anti_overfitting...\n",
      "✅ LR_anti_overfitting fitted in 342.64 seconds\n",
      "🔄 Running 8-fold cross-validation...\n",
      "✅ LR_anti_overfitting completed in 7643.9s\n",
      "   CV: 0.6382 ± 0.0432\n",
      "   Train: 0.9386\n",
      "   Val: 0.6667 (gap: 0.2719)\n",
      "💾 Model saved to: ../models/trained/LogisticRegression/lr_anti_overfitting_optimized.pkl\n",
      "\n",
      "💾 Model saved: lr_anti_overfitting_optimized.pkl\n",
      "✅ Logistic Regression optimization complete!\n"
     ]
    }
   ],
   "source": [
    "# Final optimization with best feature selection\n",
    "print(\"🎯 FINAL OPTIMIZATION - Best Feature Selection\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define parameter spaces for different optimization strategies\n",
    "anti_overfitting_space = {\n",
    "    'C': (0.001, 1.0),           # Strong regularization\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['saga'],          # saga supports l1/l2 + multiclass\n",
    "    'class_weight': ['balanced'],\n",
    "    'max_iter': (2000, 5000)\n",
    "}\n",
    "\n",
    "high_performance_space = {\n",
    "    'C': (0.1, 100.0),           # Less regularization for performance\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'newton-cg', 'sag'],  # Fast solvers for l2\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'max_iter': (1000, 3000)\n",
    "}\n",
    "\n",
    "balanced_space = {\n",
    "    'C': (0.01, 10.0),           # Balanced regularization\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['saga'],          # saga for l1/l2\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'max_iter': (1500, 4000)\n",
    "}\n",
    "\n",
    "elasticnet_space = {\n",
    "    'C': (0.001, 10.0),          # Wide regularization range\n",
    "    'penalty': ['elasticnet'],    # Only elasticnet\n",
    "    'solver': ['saga'],          # Only solver that supports elasticnet\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'max_iter': (2000, 5000),\n",
    "    'l1_ratio': (0.1, 0.9)       # Mix of l1 and l2 (only for elasticnet)\n",
    "}\n",
    "\n",
    "# Test each strategy\n",
    "spaces = {\n",
    "    'anti_overfitting': anti_overfitting_space,\n",
    "    'high_performance': high_performance_space,\n",
    "    'balanced': balanced_space,\n",
    "    'elasticnet': elasticnet_space\n",
    "}\n",
    "\n",
    "strategy_name, param_space = list(spaces.items())[0]\n",
    "\n",
    "print(f\"\\n🧪 Testing {strategy_name} strategy...\")\n",
    "\n",
    "lr_strategy = LogisticRegressionModel()\n",
    "lr_strategy.name = f\"LR_{strategy_name}\"\n",
    "\n",
    "lr_model = trainer.train_model(\n",
    "    model=lr_strategy,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val_scaled,\n",
    "    y_val=y_val,\n",
    "    param_space=param_space,\n",
    "    optimize=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "lr_name = f\"lr_{strategy_name}_optimized\"\n",
    "trainer.save_model(lr_strategy, f\"../models/trained/LogisticRegression/{lr_name}.pkl\")\n",
    "\n",
    "print(f\"\\n💾 Model saved: {lr_name}.pkl\")\n",
    "print(\"✅ Logistic Regression optimization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab44150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "304",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
