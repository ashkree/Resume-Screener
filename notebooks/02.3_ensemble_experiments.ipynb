{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d803f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52f3b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from ml_pipeline import ModelTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6afdf88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📦 Loading existing trained models...\n",
      "📂 Model loaded from: ../models/trained/RandomForest/high_performance_with_feature_selection_F-Score_1500.pkl\n",
      "   Model: Optimized_F-Score_1500\n",
      "   Fitted: True\n",
      "✅ RF model loaded: Optimized_F-Score_1500\n",
      "   Raw model type: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "   Is fitted: True\n",
      "📂 Model loaded from: ../models/trained/LogisticRegression/lr_anti_overfitting_optimized.pkl\n",
      "   Model: LR_anti_overfitting\n",
      "   Fitted: True\n",
      "✅ LR model loaded: LR_anti_overfitting\n",
      "   Raw model type: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "   Is fitted: True\n"
     ]
    }
   ],
   "source": [
    "# Initialize trainer for loading\n",
    "trainer = ModelTrainer()\n",
    "\n",
    "# =============================================================================\n",
    "# 1. LOAD YOUR EXISTING MODELS\n",
    "# =============================================================================\n",
    "print(\"\\n📦 Loading existing trained models...\")\n",
    "\n",
    "# Load RF model and extract the raw sklearn model\n",
    "try:\n",
    "    rf_wrapper = trainer.load_model('../models/trained/RandomForest/high_performance_with_feature_selection_F-Score_1500.pkl')\n",
    "    rf_sklearn_model = rf_wrapper.model  # Extract the actual RandomForestClassifier\n",
    "    print(f\"✅ RF model loaded: {rf_wrapper.name}\")\n",
    "    print(f\"   Raw model type: {type(rf_sklearn_model)}\")\n",
    "    print(f\"   Is fitted: {hasattr(rf_sklearn_model, 'classes_')}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to load RF model: {e}\")\n",
    "    rf_sklearn_model = None\n",
    "\n",
    "# Load LR model and extract the raw sklearn model\n",
    "try:\n",
    "    lr_wrapper = trainer.load_model('../models/trained/LogisticRegression/lr_anti_overfitting_optimized.pkl')\n",
    "    lr_sklearn_model = lr_wrapper.model  # Extract the actual LogisticRegression\n",
    "    print(f\"✅ LR model loaded: {lr_wrapper.name}\")\n",
    "    print(f\"   Raw model type: {type(lr_sklearn_model)}\")\n",
    "    print(f\"   Is fitted: {hasattr(lr_sklearn_model, 'classes_')}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to load LR model: {e}\")\n",
    "    lr_sklearn_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17b58bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading train/val data...\n",
      "✅ Data loaded:\n",
      "   X_train: (2100, 5000)\n",
      "   X_val: (600, 5000)\n",
      "   y_train: 2100 samples\n",
      "   y_val: 600 samples\n"
     ]
    }
   ],
   "source": [
    "# Load the original data to fit preprocessing\n",
    "from utils import load_train_val_data\n",
    "X_train, X_val, y_train, y_val = load_train_val_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ad9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌳 Creating RF pipeline with feature selection...\n",
      "   Fitting RF pipeline...\n",
      "✅ RF pipeline fitted and ready\n",
      "   Features: 5000 → 1500 (70% reduction)\n",
      "✅ RF pipeline created and tested\n",
      "   Features: 5000 → 1500 (70% reduction)\n",
      "💾 RF pipeline saved: rf_complete_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# RF Pipeline: Feature Selection (F-Score, k=1500)\n",
    "if rf_model is not None:\n",
    "    print(\"\\n🌳 Creating RF pipeline with feature selection...\")\n",
    "    \n",
    "    # Create pipeline with unfitted components first\n",
    "    rf_feature_selector = SelectKBest(f_classif, k=1500)\n",
    "    rf_pipeline = Pipeline([\n",
    "        ('feature_selection', rf_feature_selector),\n",
    "        ('model', rf_model.model)  # Use the actual sklearn model, not wrapper\n",
    "    ])\n",
    "    \n",
    "    # Fit the entire pipeline\n",
    "    print(\"   Fitting RF pipeline...\")\n",
    "    rf_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"✅ RF pipeline fitted and ready\")\n",
    "    print(f\"   Features: 5000 → 1500 (70% reduction)\")\n",
    "    \n",
    "    # Test the pipeline\n",
    "    rf_test_pred = rf_pipeline.predict(X_val[:5])  # Test on small sample\n",
    "    print(f\"✅ RF pipeline created and tested\")\n",
    "    print(f\"   Features: 5000 → 1500 (70% reduction)\")\n",
    "    \n",
    "    # Save complete RF pipeline using pickle directly (avoid ModelTrainer.save_model)\n",
    "    import os\n",
    "    import pickle\n",
    "    os.makedirs('../models/pipelines', exist_ok=True)\n",
    "    \n",
    "    with open('../models/pipelines/rf_complete_pipeline.pkl', 'wb') as f:\n",
    "        pickle.dump(rf_pipeline, f)\n",
    "    print(f\"💾 RF pipeline saved: rf_complete_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b56eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Creating LR pipeline with scaling...\n",
      "✅ LR pipeline created and tested\n",
      "   Preprocessing: Raw → Scaled (StandardScaler)\n",
      "💾 LR pipeline saved: lr_complete_pipeline.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maveron/.conda/envs/304/lib/python3.13/site-packages/sklearn/pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LR Pipeline: Standard Scaling\n",
    "if lr_model is not None:\n",
    "    print(\"\\n📊 Creating LR pipeline with scaling...\")\n",
    "    \n",
    "    # Convert sparse to dense (as done in your training)\n",
    "    if hasattr(X_train, 'toarray'):\n",
    "        X_train_dense = X_train.toarray()\n",
    "        X_val_dense = X_val.toarray()\n",
    "    else:\n",
    "        X_train_dense = X_train\n",
    "        X_val_dense = X_val\n",
    "    \n",
    "    # Create pipeline with unfitted components\n",
    "    lr_scaler = StandardScaler()\n",
    "    lr_pipeline = Pipeline([\n",
    "        ('scaler', lr_scaler),\n",
    "        ('model', lr_model.model)  # Use the actual sklearn model, not wrapper\n",
    "    ])\n",
    "    \n",
    "    # Fit the entire pipeline\n",
    "    print(\"   Fitting LR pipeline...\")\n",
    "    lr_pipeline.fit(X_train_dense, y_train)\n",
    "    \n",
    "    print(f\"✅ LR pipeline fitted and ready\")\n",
    "    print(f\"   Preprocessing: Raw → Scaled (StandardScaler)\")\n",
    "    \n",
    "    # Test the pipeline\n",
    "    lr_test_pred = lr_pipeline.predict(X_val_dense[:5])  # Test on small sample\n",
    "    \n",
    "    # Save complete LR pipeline using pickle directly\n",
    "    with open('../models/pipelines/lr_complete_pipeline.pkl', 'wb') as f:\n",
    "        pickle.dump(lr_pipeline, f)\n",
    "    print(f\"💾 LR pipeline saved: lr_complete_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsemblePipelineWrapper:\n",
    "    \"\"\"Simple wrapper to handle sparse/dense conversion\"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline, name):\n",
    "        self.pipeline = pipeline\n",
    "        self.name = name\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self  # Already fitted\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if hasattr(X, 'toarray') and 'scaler' in [step[0] for step in self.pipeline.steps]:\n",
    "            X = X.toarray()\n",
    "        return self.pipeline.predict(X)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        if hasattr(X, 'toarray') and 'scaler' in [step[0] for step in self.pipeline.steps]:\n",
    "            X = X.toarray()\n",
    "        return self.pipeline.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e53a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ensemble wrappers created:\n",
      "   - RF_FeatureSelected: Feature selection pipeline\n",
      "   - LR_Scaled: Scaling pipeline\n",
      "💾 Ensemble-ready models saved\n"
     ]
    }
   ],
   "source": [
    "# Create wrapped pipelines\n",
    "if rf_model is not None and lr_model is not None:\n",
    "    rf_ensemble = EnsemblePipelineWrapper(rf_pipeline, \"RF_FeatureSelected\")\n",
    "    lr_ensemble = EnsemblePipelineWrapper(lr_pipeline, \"LR_Scaled\")\n",
    "    \n",
    "    print(f\"✅ Ensemble wrappers created:\")\n",
    "    print(f\"   - {rf_ensemble.name}: Feature selection pipeline\")\n",
    "    print(f\"   - {lr_ensemble.name}: Scaling pipeline\")\n",
    "    \n",
    "    # Save ensemble-ready models using pickle directly\n",
    "    with open('../models/pipelines/rf_ensemble_ready.pkl', 'wb') as f:\n",
    "        pickle.dump(rf_ensemble, f)\n",
    "    with open('../models/pipelines/lr_ensemble_ready.pkl', 'wb') as f:\n",
    "        pickle.dump(lr_ensemble, f)\n",
    "    print(f\"💾 Ensemble-ready models saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba1eabe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Creating ensemble with pipelines...\n",
      "   Fitting ensemble...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The estimator Pipeline should be a classifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   Fitting ensemble...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m sample_size = \u001b[38;5;28mmin\u001b[39m(\u001b[32m100\u001b[39m, X_train.shape[\u001b[32m0\u001b[39m]) \n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mensemble\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m📊 Testing ensemble on validation data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Test with raw sparse data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/304/lib/python3.13/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/304/lib/python3.13/site-packages/sklearn/ensemble/_voting.py:405\u001b[39m, in \u001b[36mVotingClassifier.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28mself\u001b[39m.classes_ = \u001b[38;5;28mself\u001b[39m.le_.classes_\n\u001b[32m    403\u001b[39m transformed_y = \u001b[38;5;28mself\u001b[39m.le_.transform(y)\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/304/lib/python3.13/site-packages/sklearn/ensemble/_voting.py:80\u001b[39m, in \u001b[36m_BaseVoting.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, **fit_params):\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get common fit operations.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     names, clfs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.weights) != \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators):\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     84\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     85\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m estimators\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/304/lib/python3.13/site-packages/sklearn/ensemble/_base.py:237\u001b[39m, in \u001b[36m_BaseHeterogeneousEnsemble._validate_estimators\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m estimators:\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m est != \u001b[33m\"\u001b[39m\u001b[33mdrop\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_estimator_type(est):\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    238\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe estimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m should be a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    239\u001b[39m                 est.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, is_estimator_type.\u001b[34m__name__\u001b[39m[\u001b[32m3\u001b[39m:]\n\u001b[32m    240\u001b[39m             )\n\u001b[32m    241\u001b[39m         )\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m names, estimators\n",
      "\u001b[31mValueError\u001b[39m: The estimator Pipeline should be a classifier."
     ]
    }
   ],
   "source": [
    "print(\"\\n🎯 Creating ensemble with pipelines...\")\n",
    "\n",
    "if rf_model is not None and lr_model is not None:\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    \n",
    "    # Use pipelines directly - they're already sklearn-compatible\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf_pipeline),  # Use pipeline directly\n",
    "            ('lr', lr_pipeline)   # Use pipeline directly  \n",
    "        ],\n",
    "        voting='soft'\n",
    "    )\n",
    "    \n",
    "    # For LR pipeline, we need to handle sparse input conversion\n",
    "    # Create a custom predict method that handles this\n",
    "    class SmartVotingClassifier(VotingClassifier):\n",
    "        def predict(self, X):\n",
    "            # Handle sparse input for LR pipeline\n",
    "            predictions = []\n",
    "            for name, estimator in self.estimators:\n",
    "                if name == 'lr' and hasattr(X, 'toarray'):\n",
    "                    pred = estimator.predict(X.toarray())\n",
    "                else:\n",
    "                    pred = estimator.predict(X)\n",
    "                predictions.append(pred)\n",
    "            \n",
    "            # Use majority voting for final prediction\n",
    "            import numpy as np\n",
    "            from scipy import stats\n",
    "            stacked_preds = np.column_stack(predictions)\n",
    "            final_preds = stats.mode(stacked_preds, axis=1)[0].flatten()\n",
    "            return final_preds\n",
    "            \n",
    "        def predict_proba(self, X):\n",
    "            # Handle sparse input and average probabilities\n",
    "            probas = []\n",
    "            for name, estimator in self.estimators:\n",
    "                if name == 'lr' and hasattr(X, 'toarray'):\n",
    "                    proba = estimator.predict_proba(X.toarray())\n",
    "                else:\n",
    "                    proba = estimator.predict_proba(X)\n",
    "                probas.append(proba)\n",
    "            \n",
    "            # Average probabilities\n",
    "            import numpy as np\n",
    "            return np.mean(probas, axis=0)\n",
    "    \n",
    "    # Create smart ensemble\n",
    "    ensemble = SmartVotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf_pipeline),\n",
    "            ('lr', lr_pipeline)\n",
    "        ],\n",
    "        voting='soft'\n",
    "    )\n",
    "    \n",
    "    # Fit the ensemble with a small sample\n",
    "    print(\"   Fitting ensemble...\")\n",
    "    sample_size = min(100, X_train.shape[0]) \n",
    "    ensemble.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    \n",
    "    print(f\"📊 Testing ensemble on validation data...\")\n",
    "    \n",
    "    # Test with raw sparse data\n",
    "    ensemble_pred = ensemble.predict(X_val[:100])\n",
    "    ensemble_proba = ensemble.predict_proba(X_val[:100])\n",
    "    \n",
    "    print(f\"✅ Ensemble test successful!\")\n",
    "    print(f\"   Predictions shape: {ensemble_pred.shape}\")\n",
    "    print(f\"   Probabilities shape: {ensemble_proba.shape}\")\n",
    "    print(f\"   Sample prediction: {ensemble_pred[:5]}\")\n",
    "    \n",
    "    # Save the ensemble\n",
    "    with open('../models/pipelines/rf_lr_ensemble.pkl', 'wb') as f:\n",
    "        pickle.dump(ensemble, f)\n",
    "    print(f\"💾 Complete ensemble saved: rf_lr_ensemble.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d53f5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "304",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
